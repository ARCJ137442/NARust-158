//! ä¸å…¶å®ƒç±»å‹ç›¸äº’è½¬æ¢
//! * ğŸ¯è½¬æ¢ä¸ºã€Œè¯æ³•Narseseã€ä»¥ä¾¿ã€Œè·å–åç§°ã€

use super::structs::*;
use crate::symbols::*;
use anyhow::{anyhow, Result};
use nar_dev_utils::*;
use narsese::{
    api::{FormatTo, GetCapacity},
    conversion::inter_type::lexical_fold::TryFoldInto,
    lexical::Term as TermLexical,
};
use std::str::FromStr;

/// è¯é¡¹â‡’å­—ç¬¦ä¸²
/// * ğŸ¯ç”¨äºæ›´å¥½åœ°æ‰“å°ã€Œè¯é¡¹ã€åç§°
/// * ğŸ¯ç”¨äºä»ã€Œè¯æ³•Narseseã€ä¸­è§£æ
///   * è€ƒè™‘ã€Œå˜é‡è¯­ä¹‰ã€
impl Term {
    pub fn format_name(&self) -> String {
        // æ ¼å¼åŒ–æ‰€ç”¨å¸¸é‡
        const OPENER: &str = "(";
        const CLOSER: &str = ")";
        const SEPARATOR: &str = " ";

        use narsese::api::TermCapacity::*;
        use TermComponents::*;
        let id = &self.identifier;
        match &self.components {
            // ç©ºç»„åˆ†
            Empty => id.clone(),
            // åç§° | åŸå­è¯é¡¹
            Word(name) => id.clone() + name,
            // åç§° | å˜é‡è¯é¡¹
            Variable(n) => id.clone() + &n.to_string(),
            Compound(terms) => {
                match self.get_capacity() {
                    // ä¸€å…ƒ
                    Unary => {
                        // ğŸ“„ "(-- A)"
                        manipulate!(
                            String::new()
                            => {+= OPENER}#
                            => {+= id}#
                            => {+= SEPARATOR}#
                            => {+= &terms[0].format_name()}#
                            => {+= CLOSER}#
                        )
                    }
                    // äºŒå…ƒ
                    BinaryVec | BinarySet => {
                        // ğŸ“„ "(A --> B)"
                        manipulate!(
                            String::new()
                            => {+= OPENER}#
                            => {+= &terms[0].format_name()}#
                            => {+= SEPARATOR}#
                            => {+= id}#
                            => {+= SEPARATOR}#
                            => {+= &terms[1].format_name()}#
                            => {+= CLOSER}#
                        )
                    }
                    // å¤šå…ƒ
                    Vec | Set => {
                        let mut s = id.to_string() + OPENER;
                        let mut terms = terms.iter();
                        if let Some(t) = terms.next() {
                            s += &t.format_name();
                        }
                        for t in terms {
                            s += SEPARATOR;
                            s += &t.format_name();
                        }
                        s + CLOSER
                    }
                    Atom => unreachable!("å¤åˆè¯é¡¹åªå¯èƒ½æ˜¯ã€Œä¸€å…ƒã€ã€ŒäºŒå…ƒã€æˆ–ã€Œå¤šå…ƒã€"),
                }
            }
        }
    }

    /// å°è¯•ä»ã€Œè¯æ³•Narseseã€è½¬æ¢
    /// * ğŸ’­ã€2024-04-21 14:44:15ã€‘ç›®å‰æ­¤ä¸­æ–¹æ³•ã€Œç›¸è¾ƒä¿å®ˆã€
    /// * ğŸ“Œä¸è¯æ³•NarseseåŸºæœ¬å¯¹åº”ï¼ˆASCIIï¼‰
    /// * âœ…åŸºæœ¬ä¿è¯ã€Œè§£æç»“æœå‡ä¿è¯ã€åˆæ³•ã€ã€
    /// * ğŸš©ã€2024-06-13 18:39:33ã€‘ç°åœ¨æ˜¯ã€Œè¯æ³•æŠ˜å ã€ä½¿ç”¨æœ¬å¤„å®ç°
    /// * âš ï¸åœ¨ã€Œè¯æ³•æŠ˜å ã€çš„è¿‡ç¨‹ä¸­ï¼Œå³å¼€å§‹ã€Œå˜é‡åŒ¿ååŒ–ã€
    ///   * ğŸ“Œã€2024-07-02 00:40:39ã€‘éœ€è¦ä¿è¯ã€Œæ ¼å¼åŒ–ã€çš„æ˜¯ä¸ªã€Œæ•´ä½“ã€ï¼šå˜é‡åªåœ¨ã€Œæ•´ä½“ã€èŒƒå›´å†…æœ‰æ„ä¹‰
    /// * ğŸš©ã€2024-09-06 17:32:12ã€‘åœ¨ã€Œè¯æ³•æŠ˜å ã€çš„è¿‡ç¨‹ä¸­ï¼Œå³å¼€å§‹ä½¿ç”¨`make`ç³»åˆ—æ–¹æ³•
    ///   * ğŸ¯åº”å¯¹ç±»ä¼¼ã€Œ`(&&, A, A)` => `(&&, A)`ã€çš„ã€Œä¸å®Œæ•´ç®€åŒ–ã€ç°è±¡
    #[inline(always)]
    pub fn from_lexical(lexical: TermLexical) -> Result<Self> {
        fold_term(lexical, &mut FoldContext::new())
    }

    /// ä»ã€Œå†…éƒ¨Narseseã€è½¬æ¢ä¸ºã€Œè¯æ³•Narseseã€
    /// * ğŸš©åŸºæœ¬æ— æŸè½¬æ¢ï¼ˆæ— éœ€è€ƒè™‘å¤±è´¥æƒ…å†µï¼‰
    pub fn to_lexical(&self) -> TermLexical {
        use TermComponents::*;
        type LTerm = TermLexical;
        let (id, comp) = self.id_comp();
        match (id, comp) {
            // ä¸“ç”¨ / é›†åˆè¯é¡¹ | é»˜è®¤å·²æ’åº
            (SET_EXT_OPERATOR, Compound(v)) => {
                let v = v.iter().map(Self::to_lexical).collect::<Vec<_>>();
                LTerm::new_set(SET_EXT_OPENER, v, SET_EXT_CLOSER)
            }
            (SET_INT_OPERATOR, Compound(v)) => {
                let v = v.iter().map(Self::to_lexical).collect::<Vec<_>>();
                LTerm::new_set(SET_INT_OPENER, v, SET_INT_CLOSER)
            }
            //  é™ˆè¿°
            (
                INHERITANCE_RELATION | SIMILARITY_RELATION | IMPLICATION_RELATION
                | EQUIVALENCE_RELATION,
                Compound(terms),
            ) if terms.len() == 2 => {
                LTerm::new_statement(id, (&terms[0]).into(), (&terms[1]).into())
            }
            // é€šç”¨ / ç©ºï¼šä»…å‰ç¼€
            (_, Empty) => LTerm::new_atom(id, ""),
            // é€šç”¨ / å…·åï¼šå‰ç¼€+è¯é¡¹å
            (_, Word(name)) => LTerm::new_atom(id, name),
            // é€šç”¨ / å˜é‡ï¼šå‰ç¼€+å˜é‡ç¼–å·
            (_, Variable(num)) => LTerm::new_atom(id, num.to_string()),
            // é€šç”¨ / å¤šå…ƒ
            (_, Compound(terms)) => {
                LTerm::new_compound(id, terms.iter().map(Self::to_lexical).collect())
            }
        }
    }

    /// è½¬æ¢ä¸ºæ˜¾ç¤ºå‘ˆç°ä¸Šçš„ASCIIæ ¼å¼
    /// * ğŸ“Œå¯¹æ ‡OpenNARSçš„é»˜è®¤å‘ˆç°
    /// * âš ï¸ã€2024-07-02 00:52:54ã€‘ç›®å‰éœ€è¦ã€Œè¯æ³•Narseseã€ä½œä¸ºä¸­é—´æ ¼å¼ï¼Œå¯èƒ½ä¼šæœ‰æ€§èƒ½æŸå¤±
    pub fn to_display_ascii(&self) -> String {
        use narsese::conversion::string::impl_lexical::format_instances::FORMAT_ASCII;
        self.to_lexical().format_to(&FORMAT_ASCII)
    }

    /// å°è¯•ä»ã€Œæ–¹è¨€ã€è½¬æ¢
    /// * ğŸ¯æ”¯æŒã€Œæ–¹è¨€è§£æã€
    /// * ğŸ“Œã€2024-05-15 02:33:13ã€‘ç›®å‰ä»åªæœ‰ã€Œä»å­—ç¬¦ä¸²åˆ°è¯é¡¹ã€è¿™ä¸€ç§å½¢å¼
    /// * ğŸ†•é™„åŠ åŠŸèƒ½ï¼Œä¸æ ¸å¿ƒã€Œæ•°æ®ç®—æ³•ã€ã€Œæ¨ç†æ§åˆ¶ã€æ— å…³
    #[inline(always)]
    #[cfg(feature = "dialect_parser")]
    pub fn from_dialect(input: &str) -> Result<Self> {
        use super::super::dialect::parse_term;
        parse_term(input)
    }
}

// * ğŸš©æ­¤å¤„çš„ã€Œå˜é‡è¯é¡¹ã€ä¸€å¼€å§‹å°±åº”è¯¥æ˜¯ä¸ªæ•°å€¼ï¼Œä»ã€Œå…·åå˜é‡ã€å˜ä¸ºã€Œæ•°å­—å˜é‡ã€
/// è¯é¡¹â‡’è¯æ³•Narsese
impl From<&Term> for TermLexical {
    fn from(term: &Term) -> Self {
        term.to_lexical()
    }
}

impl From<TermComponents> for Vec<Term> {
    /// å°†ã€Œè¯é¡¹ç»„åˆ†ã€è½¬æ¢ä¸ºã€Œå¯å˜æ•°ç»„<è¯é¡¹>ã€
    /// * ğŸš©åŸå­è¯é¡¹â‡’ç©ºæ•°ç»„
    /// * ğŸš©å¤åˆè¯é¡¹â‡’å…¶å†…æ‰€æœ‰è¯é¡¹æ„æˆçš„æ•°ç»„
    fn from(value: TermComponents) -> Self {
        use TermComponents::*;
        match value {
            Empty | Word(..) | Variable(..) => vec![],
            Compound(terms) => terms.into(),
        }
    }
}

impl From<TermComponents> for Box<[Term]> {
    /// å°†ã€Œè¯é¡¹ç»„åˆ†ã€è½¬æ¢ä¸ºã€Œå®šé•¿æ•°ç»„<è¯é¡¹>ã€
    /// * ğŸš©åŸå­è¯é¡¹â‡’ç©ºæ•°ç»„
    /// * ğŸš©å¤åˆè¯é¡¹â‡’å…¶å†…æ‰€æœ‰è¯é¡¹æ„æˆçš„æ•°ç»„
    /// * â„¹ï¸ä¸ä¸Šè¿°å¯¹[`Vec`]çš„è½¬æ¢ä¸åŒï¼šæ­¤å¤„ç›´æ¥ä½¿ç”¨`Box::new([])`æ„é€ ç©ºæ•°ç»„
    fn from(value: TermComponents) -> Self {
        use TermComponents::*;
        match value {
            Empty | Word(..) | Variable(..) => Box::new([]),
            Compound(terms) => terms,
        }
    }
}

/// è¯æ³•æŠ˜å  / è·å–ã€Œæ ‡è¯†ç¬¦ã€
/// * ğŸ¯ä»ã€Œè¯æ³•Narseseã€è·å–ã€Œæ ‡è¯†ç¬¦ã€ï¼Œä»¥ä¾¿åç»­æ ¹æ®ã€Œæ ‡è¯†ç¬¦ã€åˆ†å‘é€»è¾‘
/// * ğŸš©å¯¹ã€Œé›†åˆã€è¯é¡¹ï¼šå°†å·¦å³æ‹¬å¼§ç›´æ¥æ‹¼æ¥ï¼Œä½œä¸ºæ–°çš„ã€ç»Ÿä¸€çš„ã€Œæ ‡è¯†ç¬¦ã€
fn get_identifier(term: &TermLexical) -> String {
    match term {
        TermLexical::Atom { prefix, .. } => prefix.clone(),
        TermLexical::Compound { connecter, .. } => connecter.clone(),
        TermLexical::Set {
            left_bracket,
            right_bracket,
            ..
        } => left_bracket.to_string() + right_bracket,
        TermLexical::Statement { copula, .. } => copula.clone(),
    }
}

/// è¯æ³•æŠ˜å çš„ä¸Šä¸‹æ–‡å¯¹è±¡
/// * ğŸ¯ç»Ÿä¸€å­˜å‚¨å¦‚ã€Œå˜é‡idæ˜ å°„ã€çš„ä¸´æ—¶çŠ¶æ€
#[derive(Debug, Clone)]
struct FoldContext {
    /// æœ‰å…³ã€Œå˜é‡idâ‡’è¯é¡¹åç§°ã€çš„æ˜ å°„
    var_id_map: Vec<String>,
}

impl FoldContext {
    /// åˆ›å»ºä¸€ä¸ªæ–°çš„ä¸Šä¸‹æ–‡
    fn new() -> Self {
        Self { var_id_map: vec![] }
    }
}

/// æ ¹éƒ¨æŠ˜å ï¼ˆå¸¦ã€Œå˜é‡ç¼–å·åŒ–ã€é€»è¾‘ï¼‰
/// * ğŸš©æ¥å—åˆå§‹åŒ–åçš„æ•°ç»„
/// * â„¹ï¸å¯èƒ½è¢«é€’å½’è°ƒç”¨
/// * ğŸš©å¤§ä½“è°ƒç”¨æµç¨‹ï¼š`conversion` => `term_making` => `construct`
///   * ã€æŠ˜å ã€‘æ—¶ã€åˆ¶ä½œã€‘è¯é¡¹ï¼Œæœ€ç»ˆæ‰ã€æ„é€ ã€‘
///   * ğŸš§ã€2024-09-06 17:43:36ã€‘æœ‰å¾…å®è£…
fn fold_term(term: TermLexical, context: &mut FoldContext) -> Result<Term> {
    // TODO: ç†æ¸…ã€ŒæŠ˜å æ—¶ç®€åŒ–ã€ä¸ã€Œmakeã€çš„ åŒºåˆ«/å·®å¼‚
    // ? â“ç®€åŒ–çš„æ—¶æœº
    // ? â“æ˜¯å¦è¦ã€Œè¾¹è§£æè¾¹ç®€åŒ–ã€ã€Œå†…éƒ¨å…ƒç´ è§£æç®€åŒ–åå†åˆ°æ­¤å¤„ã€
    // TODO: ç®€åŒ–å…¶ä¸­çš„ã€Œmakeã€ç›¸å…³é€‰é¡¹

    /// æ›´æ–°å¹¶è¿”å›ä¸€ä¸ªã€Œå˜é‡è¯é¡¹ã€ï¼Œæ ¹æ®ä¼ å…¥çš„ã€Œå˜é‡idæ˜ å°„ã€å°†åŸã€Œå˜é‡åã€æ˜ å°„åˆ°ã€Œå˜é‡idã€
    #[inline]
    fn update_var(
        original_name: String,
        context: &mut FoldContext,
        new_var_from_id: fn(usize) -> Term, // * ğŸ“ä¸ç”¨ç‰¹æ„å¼•ç”¨
    ) -> Term {
        match context
            .var_id_map
            .iter()
            .position(|stored_name| &original_name == stored_name)
        {
            // * ğŸš©idä»1å¼€å§‹
            Some(existed) => new_var_from_id(existed + 1),
            // * ğŸš©æ–°åç§°
            None => {
                context.var_id_map.push(original_name);
                new_var_from_id(context.var_id_map.len())
            }
        }
    }

    macro_rules! è¯é¡¹ç®€åŒ–å¤±è´¥ {
        () => {
            anyhow::anyhow!("è¯é¡¹ç®€åŒ–å¤±è´¥ @ {}:{}", file!(), line!())
        };
    }

    // æ­£å¼å¼€å§‹
    let identifier = get_identifier(&term);
    // åœ¨æœ‰é™çš„æ ‡è¯†ç¬¦èŒƒå›´å†…åŒ¹é…
    use TermLexical::*;
    let term = match (identifier.as_str(), term) {
        // åŸå­è¯é¡¹ | âš ï¸è™½ç„¶ã€Œå•ç‹¬çš„å ä½ç¬¦ã€åœ¨OpenNARSä¸­ä¸åˆæ³•ï¼Œä½†åœ¨è§£æã€Œåƒã€æ—¶éœ€è¦ç”¨åˆ° //
        (WORD, Atom { name, .. }) => Term::new_word(name),
        (PLACEHOLDER, Atom { .. }) => Term::new_placeholder(),
        (VAR_INDEPENDENT, Atom { name, .. }) => update_var(name, context, Term::new_var_i),
        (VAR_DEPENDENT, Atom { name, .. }) => update_var(name, context, Term::new_var_d),
        (VAR_QUERY, Atom { name, .. }) => update_var(name, context, Term::new_var_q),
        // å¤åˆè¯é¡¹ //
        (SET_EXT_OPERATOR, Set { terms, .. }) => {
            Term::make_set_ext_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?
        }
        (SET_INT_OPERATOR, Set { terms, .. }) => {
            Term::make_set_int_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?
        }
        (INTERSECTION_EXT_OPERATOR, Compound { terms, .. }) => {
            Term::make_intersection_ext_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?
        }
        (INTERSECTION_INT_OPERATOR, Compound { terms, .. }) => {
            Term::make_intersection_int_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?
        }
        (DIFFERENCE_EXT_OPERATOR, Compound { terms, .. }) if terms.len() == 2 => {
            let mut iter = terms.into_iter();
            let term1 = fold_inner_lexical(iter.next().unwrap(), context)?;
            let term2 = fold_inner_lexical(iter.next().unwrap(), context)?;
            Term::make_difference_ext(term1, term2).ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?
        }
        (DIFFERENCE_INT_OPERATOR, Compound { terms, .. }) if terms.len() == 2 => {
            let mut iter = terms.into_iter();
            let term1 = fold_inner_lexical(iter.next().unwrap(), context)?;
            let term2 = fold_inner_lexical(iter.next().unwrap(), context)?;
            Term::make_difference_int(term1, term2).ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?
        }
        (PRODUCT_OPERATOR, Compound { terms, .. }) => {
            Term::make_product_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?
        }
        (IMAGE_EXT_OPERATOR, Compound { terms, .. }) => {
            // ! âš ï¸ç°åœ¨è§£æå‡ºä½œä¸ºã€Œåƒä¹‹å†…å®¹ã€çš„ã€Œè¯é¡¹åºåˆ—ã€åŒ…å«ã€Œå ä½ç¬¦ã€ä½œä¸ºå†…å®¹
            let (i, terms) = fold_lexical_terms_as_image(terms, context)?;
            match i {
                // å ä½ç¬¦åœ¨é¦–ä½â‡’è§†ä½œã€Œä¹˜ç§¯ã€ | ğŸ“NAL-4ä¸­ä¿ç•™ã€Œç¬¬0ä½ã€ä½œã€Œå…³ç³»ã€è¯é¡¹
                0 => Term::make_product_arg(terms).ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
                _ => Term::new_image_ext(terms)?,
            }
        }
        (IMAGE_INT_OPERATOR, Compound { terms, .. }) => {
            // ! âš ï¸ç°åœ¨è§£æå‡ºä½œä¸ºã€Œåƒä¹‹å†…å®¹ã€çš„ã€Œè¯é¡¹åºåˆ—ã€åŒ…å«ã€Œå ä½ç¬¦ã€ä½œä¸ºå†…å®¹
            let (i, terms) = fold_lexical_terms_as_image(terms, context)?;
            match i {
                // å ä½ç¬¦åœ¨é¦–ä½â‡’è§†ä½œã€Œä¹˜ç§¯ã€ | ğŸ“NAL-4ä¸­ä¿ç•™ã€Œç¬¬0ä½ã€ä½œã€Œå…³ç³»ã€è¯é¡¹
                0 => Term::make_product_arg(terms).ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
                _ => Term::new_image_int(terms)?,
            }
        }
        (CONJUNCTION_OPERATOR, Compound { terms, .. }) => {
            Term::make_conjunction_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?
        }
        (DISJUNCTION_OPERATOR, Compound { terms, .. }) => {
            Term::make_disjunction_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?
        }
        (NEGATION_OPERATOR, Compound { terms, .. }) if terms.len() == 1 => {
            // TODO: æå–å½¢å¦‚ã€Œæ•°ç»„ä¸­ã€åˆ¤æ–­æŒ‡å®šæ•°é‡å¹¶å–å‡ºæ•°ç»„ã€ã€çš„è¯­ä¹‰ `fn extract_term_vec<const N: usize>(terms: Vec<Term>) -> Result<[Term; N]>`
            // * ğŸ’¡ä½¿ç”¨ã€Œå ä½ç¬¦ã€ä½œä¸ºã€Œæ•°ç»„åˆå§‹åŒ–ã€çš„å ä½ç¬¦
            let inner = fold_inner_lexical(terms.into_iter().next().unwrap(), context)?;
            Term::make_negation(inner).ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?
        }
        // é™ˆè¿°
        (
            INHERITANCE_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_inheritance(
            fold_inner_lexical(*subject, context)?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
        (
            SIMILARITY_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_similarity(
            fold_inner_lexical(*subject, context)?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
        (
            IMPLICATION_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_implication(
            fold_inner_lexical(*subject, context)?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
        (
            EQUIVALENCE_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_equivalence(
            fold_inner_lexical(*subject, context)?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
        (
            INSTANCE_RELATION, // æ´¾ç”Ÿç³»è¯/å®ä¾‹
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_inheritance(
            Term::make_set_ext_arg(vec![fold_inner_lexical(*subject, context)?])
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
        (
            PROPERTY_RELATION, // æ´¾ç”Ÿç³»è¯/å±æ€§
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_inheritance(
            fold_inner_lexical(*subject, context)?,
            Term::make_set_int_arg(vec![fold_inner_lexical(*predicate, context)?])
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
        )
        .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
        (
            INSTANCE_PROPERTY_RELATION, // æ´¾ç”Ÿç³»è¯/å®ä¾‹å±æ€§
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_inheritance(
            Term::make_set_ext_arg(vec![fold_inner_lexical(*subject, context)?])
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
            Term::make_set_int_arg(vec![fold_inner_lexical(*predicate, context)?])
                .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
        )
        .ok_or(è¯é¡¹ç®€åŒ–å¤±è´¥!())?,
        // å…¶å®ƒæƒ…å†µâ‡’ä¸åˆæ³•
        (identifier, this) => return Err(anyhow!("æ ‡è¯†ç¬¦ä¸ºã€Œ{identifier}ã€çš„éæ³•è¯é¡¹ï¼š{this:?}")),
    };
    Ok(term)
}

/// è¯æ³•æŠ˜å /å•ä¸ªè½¬æ¢
/// * âš ï¸æ‹’ç»å‘ˆé€’å ä½ç¬¦ï¼šä¸å…è®¸ã€Œåƒå ä½ç¬¦ã€åœ¨é™¤äº†ã€Œå¤–å»¶åƒ/å†…æ¶µåƒã€å¤–çš„è¯é¡¹ä¸­å‡ºç°
#[inline]
fn fold_inner_lexical(term: TermLexical, context: &mut FoldContext) -> Result<Term> {
    // * ğŸš©æ­£å¸¸è½¬æ¢
    let term = fold_term(term, context)?;
    // * ğŸš©æ‹¦æˆªè§£æå‡ºçš„ã€Œå ä½ç¬¦ã€è¯é¡¹
    if term.is_placeholder() {
        return Err(anyhow!("è¯æ³•æŠ˜å é”™è¯¯ï¼šå ä½ç¬¦ä»…èƒ½ç›´å±äº å¤–å»¶åƒ/å†…æ¶µåƒ è¯é¡¹"));
    }
    // * ğŸš©æ­£å¸¸è¿”å›
    Ok(term)
}

/// è¯æ³•æŠ˜å  / ä»ã€Œæ•°ç»„ã€ä¸­è½¬æ¢
/// * ğŸ¯å°†ã€Œè¯æ³•Narseseè¯é¡¹æ•°ç»„ã€è½¬æ¢ä¸ºã€Œå†…éƒ¨è¯é¡¹æ•°ç»„ã€
///   * ğŸ“„ç”¨äºå¤åˆè¯é¡¹å†…éƒ¨å…ƒç´ çš„è§£æ
///   * â„¹ï¸å¯¹äºã€Œå¤–å»¶åƒ/å†…æ¶µåƒã€é‡‡ç”¨ç‰¹æ®Šæ–¹æ³•
/// * ğŸ“Œåœ¨ã€Œæ— æ³•åŒæ—¶`map`ä¸`?`ã€æ—¶ç‹¬ç«‹æˆå‡½æ•°
/// * âš ï¸ä¸å…è®¸æ„é€ ç©ºè¯é¡¹æ•°ç»„ï¼šå‚è€ƒNALï¼Œä¸å…è®¸ç©ºé›†
/// * âŒã€2024-07-08 23:20:02ã€‘ç°ä¸å…è®¸åœ¨å…¶ä¸­è§£æå‡ºã€Œå ä½ç¬¦ã€è¯é¡¹
///   * ğŸ¯ææ—©é¿å…ã€Œåƒå ä½ç¬¦æº¢å‡ºã€æƒ…å½¢
#[inline]
fn fold_inner_lexical_vec(terms: Vec<TermLexical>, context: &mut FoldContext) -> Result<Vec<Term>> {
    let mut v = vec![];
    for term in terms {
        v.push(fold_inner_lexical(term, context)?);
    }
    check_folded_terms(v)
}

#[inline]

/// æ£€æŸ¥æŠ˜å å¥½äº†çš„è¯é¡¹è¡¨
/// * ğŸš©ã€2024-06-14 00:13:29ã€‘ç›®å‰ä»…æ£€æŸ¥ã€Œæ˜¯å¦ä¸ºç©ºé›†ã€
fn check_folded_terms(v: Vec<Term>) -> Result<Vec<Term>> {
    match v.is_empty() {
        true => Err(anyhow!("è¯æ³•æŠ˜å é”™è¯¯ï¼šNALä¸å…è®¸æ„é€ ç©ºé›†")),
        false => Ok(v),
    }
}

/// è¯æ³•æŠ˜å  / ä»ã€Œæ•°ç»„ã€ä¸­è½¬æ¢æˆã€Œåƒã€
/// * ğŸ¯å°†ã€Œè¯æ³•Narseseè¯é¡¹æ•°ç»„ã€è½¬æ¢ä¸ºã€Œåƒã€æ‰€éœ€çš„ã€Œå¸¦ç´¢å¼•è¯é¡¹æ•°ç»„ã€
#[inline]
fn fold_lexical_terms_as_image(
    terms: Vec<TermLexical>,
    context: &mut FoldContext,
) -> Result<(usize, Vec<Term>)> {
    // æ„é€ ã€Œç»„åˆ†ã€
    let mut v = vec![];
    let mut placeholder_index = 0;
    for (i, term) in terms.into_iter().enumerate() {
        let term: Term = fold_term(term, context)?;
        // è¯†åˆ«ã€Œå ä½ç¬¦ä½ç½®ã€
        // ğŸ†•ã€2024-04-21 01:12:50ã€‘ä¸åŒäºOpenNARSï¼šåªä¼šç•™ä¸‹ï¼ˆä¸”ä½ç½®å–å†³äºï¼‰æœ€åä¸€ä¸ªå ä½ç¬¦
        // ğŸ“„OpenNARSåœ¨ã€Œæ²¡æ‰¾åˆ°å ä½ç¬¦ã€æ—¶ï¼Œä¼šå°†ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºå ä½ç¬¦ï¼Œç„¶åæŠŠã€Œå ä½ç¬¦ç´¢å¼•ã€å›ºå®šä¸º`1`
        match term.is_placeholder() {
            true => {
                placeholder_index = i;
                if i > 0 {
                    // * ğŸš©å ä½ç¬¦ä¸èƒ½æ˜¯ç¬¬ä¸€ä¸ªâ‡’å¦åˆ™ä½œä¸ºã€Œä¹˜ç§¯ã€æäº¤ï¼ˆä¸åŒ…å«å ä½ç¬¦ï¼‰
                    v.push(term);
                }
            }
            // * ğŸš©ç°åœ¨é™¤äº†ã€Œå ä½ç¬¦åœ¨ç¬¬ä¸€ä¸ªã€ï¼ˆä¹˜ç§¯ï¼‰çš„æƒ…å½¢ï¼Œå…¶å®ƒå‡å°†ã€Œå ä½ç¬¦ã€ç®—å…¥åœ¨ã€Œå…ƒç´ ã€ä¸­
            false => v.push(term),
        }
    }
    Ok((placeholder_index, check_folded_terms(v)?))
}

/// è¯æ³•æŠ˜å 
impl TryFoldInto<'_, Term, anyhow::Error> for TermLexical {
    type Folder = ();

    fn try_fold_into(self, _: &'_ Self::Folder) -> Result<Term> {
        Term::from_lexical(self)
    }
}

/// åŸºäºã€Œè¯æ³•æŠ˜å ã€å®ç°[`TryFrom`]
impl TryFrom<TermLexical> for Term {
    type Error = anyhow::Error;

    #[inline(always)]
    fn try_from(value: TermLexical) -> Result<Self, Self::Error> {
        value.try_fold_into(&())
    }
}

/// å­—ç¬¦ä¸²è§£æè·¯çº¿ï¼šè¯æ³•è§£æ â‡’ è¯æ³•æŠ˜å 
/// * ğŸ¯åŒæ—¶å…¼å®¹[`str::parse`]ä¸[`str::try_into`]
/// * ğŸ“Œä½¿ç”¨æ ‡å‡†OpenNARS ASCIIè¯­æ³•
impl TryFrom<&str> for Term {
    type Error = anyhow::Error;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        use narsese::conversion::string::impl_lexical::format_instances::FORMAT_ASCII;
        // è¯æ³•è§£æ
        let lexical = FORMAT_ASCII.parse(s)?;
        // è¯æ³•è½¬æ¢ | âš ï¸å¯¹ã€Œè¯­å¥ã€ã€Œä»»åŠ¡ã€æŠ¥é”™
        let term = lexical.try_into_term()?;
        // è¯æ³•æŠ˜å 
        let term = term.try_into()?;
        // è¿”å›
        Ok(term)
    }
}

///  å­—ç¬¦ä¸²è§£æ
/// * ğŸ¯åŒæ—¶å…¼å®¹[`str::parse`]ä¸[`str::try_into`]
impl FromStr for Term {
    type Err = anyhow::Error;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        s.try_into()
    }
}

/// å•å…ƒæµ‹è¯•
#[cfg(test)]
mod tests {
    use super::*;
    use crate::{ok, util::AResult};
    use narsese::{
        conversion::{
            inter_type::lexical_fold::TryFoldInto,
            string::impl_lexical::format_instances::FORMAT_ASCII,
        },
        lexical::Term as LexicalTerm,
        lexical_nse_term as l_term,
    };

    /// æµ‹è¯• / è¯æ³•æŠ˜å 
    #[test]
    fn test_lexical_fold() -> AResult {
        fn test(t: LexicalTerm) -> Result<Term> {
            print!("{:?} => ", FORMAT_ASCII.format(&t));
            // ä¸‰ç§è§£æè·¯å¾„
            let term_1 = Term::try_from(t.clone())?;
            let term_2 = t.clone().try_fold_into(&())?;
            let term_3 = Term::from_lexical(t)?;
            // åˆ¤æ–­è·¯å¾„ç­‰ä»·æ€§
            assert_eq!(term_1, term_2);
            assert_eq!(term_1, term_3);
            assert_eq!(term_2, term_3);
            // æ‰“å°
            let term = term_1;
            println!("{:?}", term.format_name());
            Ok(term)
        }
        macro_once! {
            // * ğŸš©æ¨¡å¼ï¼šè¯é¡¹å­—ç¬¦ä¸²
            macro test($($term:literal)*) {
                $(
                    test(l_term!($term))?;
                )*
            }
            "<A --> B>"
            "(&&, C, B, A, (/, A, _, B))"
            // "<(*, {SELF}, x, y) --> ^left>" // ! âš ï¸ã€2024-04-25 10:02:20ã€‘ç°åœ¨å¯¹ã€Œæ“ä½œç¬¦ã€ä¸å†æ”¯æŒ
            "[2, 1, 0, $0, #1, ?2]"
            "<A <-> {B}>" // ! åŸå…ˆçš„ã€Œç±»é‡è¨€å¼ã€`<A <-> {A}>`æ˜¯æ— æ•ˆçš„
            "<{A} <=> B>" // ! åŸå…ˆçš„ã€Œç±»é‡è¨€å¼ã€`<{B} <=> B>`æ˜¯æ— æ•ˆçš„
            "<{SELF} ==> (--, [good])>"
        }
        ok!()
    }

    /// æµ‹è¯• / è¯æ³•æŠ˜å /å¤±è´¥æƒ…å†µ
    /// * âš ï¸ä»…è€ƒè™‘è¯æ³•æŠ˜å å¤±è´¥ï¼Œä¸è€ƒè™‘è§£æå¤±è´¥
    #[test]
    fn test_lexical_fold_err() -> AResult {
        fn test(t: LexicalTerm) -> AResult {
            let t_s = FORMAT_ASCII.format(&t);
            let e = Term::try_from(t.clone()).expect_err(&format!("éæ³•è¯é¡¹{t_s:?}å¼‚å¸¸é€šè¿‡è§£æ"));
            println!("{t_s:?} => {e}");
            ok!()
        }
        macro_once! {
            // * ğŸš©æ¨¡å¼ï¼šè¯é¡¹å­—ç¬¦ä¸²
            macro test($($term:literal)*) {
                $(
                    test(l_term!($term))?;
                )*
            }
            // * ğŸ“„éæ³•æ ‡è¯†ç¬¦
            // * ğŸš©ã€2024-04-25 10:02:20ã€‘ç°åœ¨å¯¹ã€Œæ“ä½œç¬¦ã€ä¸å†æ”¯æŒ
            "^operator" // ^operator
            "<(*, {SELF}, x, y) --> ^left>" // ^left
            "<X =/> Y>" // =/>
            "<X =|> Y>" // =|>
            "<X </> Y>" // </>
            "+123" // +123
            "(&/, 1, 2, 3)" // &/
            "(&|, 3, 2, 1)" // &|
            // * ğŸ“„è¯é¡¹æ•°ç›®ä¸å¯¹
            "(-, A, B, C)"
            "(-, A)"
            "(--, A, B)"
            // * ğŸ“„ç©ºé›†
            // * ğŸ“„æº¢å‡ºçš„å ä½ç¬¦
            "{_}"
            "{A, B, _}"
            "[_]"
            "[A, B, _]"
            "<A --> _>"
            "<A <-> _>"
            "<A ==> _>"
            "<A <=> _>"
            "<_ --> _>"
            "<_ <-> _>"
            "<_ ==> _>"
            "<_ <=> _>"
            "(&, _, A, B)"
            "(-, _, B)"
            "(-, A, _)"
            "(--, _)"
            "(&&, (*, [A, B, _]), A, B)"
        }
        ok!()
    }

    /// æµ‹è¯• / å˜é‡é‡ç¼–å·
    /// * ğŸ“„nse  `<(&&,<(*,{$1},{$2},$d)-->æ–¹å‘>,<(*,{$1},$c)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$2},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>)==><(*,$d,$c,{$1},{$2})-->[åŒè‰²è¿ç©º]>>.%1.00;0.99%`
    ///   * ğŸ•’ã€2024-07-02 00:32:46ã€‘
    ///   * é¢„æœŸï¼š`<(&&,<(*,{$1},{$2},$3)-->æ–¹å‘>,<(*,{$1},$4)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$2},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>)==><(*,$3,$4,{$1},{$2})-->[åŒè‰²è¿ç©º]>>. %1.0;0.99%`
    ///   * å½“å‰ï¼š`<(&&,<(*,{$1},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$1},$2)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$1},{$2},$3)-->æ–¹å‘>)==><(*,$1,$2,{$3},{$4})-->[åŒè‰²è¿ç©º]>>.%1.0000;0.9900%`
    ///   * é¢„æœŸã®æ˜ å°„ï¼š
    ///     * `$1` => `$1`
    ///     * `$2` => `$2`
    ///     * `$d` => `$3`
    ///     * `$c` => `$4`
    ///   * å½“å‰ã®æ˜ å°„ï¼š
    ///     * `$1` => `$1`
    ///     * `$2` => `$2`ã€`$1`@ã€Œæ— ç¼ºé™·ã€
    ///     * `$d` => `$3`ã€`$1`@åŒè‰²è¿ç©º
    ///     * `$c` => `$2`
    /// * âœ…ã€2024-07-02 01:06:12ã€‘ç°åœ¨æˆåŠŸï¼šè‡³å°‘æ˜¯å”¯ä¸€æ˜ å°„äº†
    ///     * `$1` => `$1`
    ///     * `$2` => `$2`
    ///     * `$d` => `$4`
    ///     * `$c` => `$3`
    #[test]
    fn test_var_map() -> AResult {
        // è¯æ³•Narseseå±•ç¤º
        let lexical = l_term!(<(&&,<(*,{$1},{$2},$d)-->æ–¹å‘>,<(*,{$1},$c)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$2},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>)==><(*,$d,$c,{$1},{$2})-->[åŒè‰²è¿ç©º]>>);
        println!("{}", FORMAT_ASCII.format(&lexical));

        // è¯æ³•æŠ˜å 
        let term1 = Term::from_lexical(lexical.clone())?;
        let term1_s = term1.to_display_ascii();
        println!("{term1_s}");

        // å†…éƒ¨æŠ˜å æ–¹æ³•
        let mut context = FoldContext::new();
        let term2 = fold_term(lexical.clone(), &mut context)?;
        let term2_s = term2.to_display_ascii();
        println!("{term2_s}");
        assert_eq!(term1_s, term2_s); // ä¸¤ç§è½¬æ¢ä¹‹åï¼Œå­—ç¬¦ä¸²å½¢å¼åº”è¯¥ç›¸ç­‰

        // å¯¹æ¯”ï¼šæ˜ å°„è¡¨
        println!("{:?}", context);
        for (var_i, original_name) in context.var_id_map.iter().enumerate() {
            println!("{original_name} => {}", var_i + 1);
        }
        let expected = [("1", 1), ("2", 2), ("d", 3), ("c", 4)];
        for (original_name, var_i) in expected.iter() {
            // æ–­è¨€æ˜ å°„è¡¨ç›¸ç­‰
            assert_eq!(context.var_id_map[*var_i - 1], *original_name);
        }
        ok!()
    }
}
