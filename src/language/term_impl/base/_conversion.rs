//! ä¸å…¶å®ƒç±»å‹ç›¸äº’è½¬æ¢
//! * ğŸ¯è½¬æ¢ä¸ºã€Œè¯æ³•Narseseã€ä»¥ä¾¿ã€Œè·å–åç§°ã€

use super::structs::*;
use crate::io::symbols::*;
use anyhow::{anyhow, Result};
use nar_dev_utils::*;
use narsese::{
    api::{FormatTo, GetCapacity},
    conversion::inter_type::lexical_fold::TryFoldInto,
    lexical::Term as TermLexical,
};
use std::str::FromStr;

/// è¯é¡¹â‡’å­—ç¬¦ä¸²
/// * ğŸ¯ç”¨äºæ›´å¥½åœ°æ‰“å°ã€Œè¯é¡¹ã€åç§°
/// * ğŸ¯ç”¨äºä»ã€Œè¯æ³•Narseseã€ä¸­è§£æ
///   * è€ƒè™‘ã€Œå˜é‡è¯­ä¹‰ã€
impl Term {
    pub fn format_name(&self) -> String {
        // æ ¼å¼åŒ–æ‰€ç”¨å¸¸é‡
        const OPENER: &str = "(";
        const CLOSER: &str = ")";
        const SEPARATOR: &str = " ";

        use narsese::api::TermCapacity::*;
        use TermComponents::*;
        let id = &self.identifier;
        match &self.components {
            // ç©ºç»„åˆ†
            Empty => id.clone(),
            // åç§° | åŸå­è¯é¡¹
            Word(name) => id.clone() + name,
            // åç§° | å˜é‡è¯é¡¹
            Variable(n) => id.clone() + &n.to_string(),
            Compound(terms) => {
                match self.get_capacity() {
                    // ä¸€å…ƒ
                    Unary => {
                        // ğŸ“„ "(-- A)"
                        manipulate!(
                            String::new()
                            => {+= OPENER}#
                            => {+= id}#
                            => {+= SEPARATOR}#
                            => {+= &terms[0].format_name()}#
                            => {+= CLOSER}#
                        )
                    }
                    // äºŒå…ƒ
                    BinaryVec | BinarySet => {
                        // ğŸ“„ "(A --> B)"
                        manipulate!(
                            String::new()
                            => {+= OPENER}#
                            => {+= &terms[0].format_name()}#
                            => {+= SEPARATOR}#
                            => {+= id}#
                            => {+= SEPARATOR}#
                            => {+= &terms[1].format_name()}#
                            => {+= CLOSER}#
                        )
                    }
                    // å¤šå…ƒ
                    Vec | Set => {
                        let mut s = id.to_string() + OPENER;
                        let mut terms = terms.iter();
                        if let Some(t) = terms.next() {
                            s += &t.format_name();
                        }
                        for t in terms {
                            s += SEPARATOR;
                            s += &t.format_name();
                        }
                        s + CLOSER
                    }
                    Atom => unreachable!("å¤åˆè¯é¡¹åªå¯èƒ½æ˜¯ã€Œä¸€å…ƒã€ã€ŒäºŒå…ƒã€æˆ–ã€Œå¤šå…ƒã€"),
                }
            }
        }
    }

    /// å°è¯•ä»ã€Œè¯æ³•Narseseã€è½¬æ¢
    /// * ğŸ’­ã€2024-04-21 14:44:15ã€‘ç›®å‰æ­¤ä¸­æ–¹æ³•ã€Œç›¸è¾ƒä¿å®ˆã€
    /// * ğŸ“Œä¸è¯æ³•NarseseåŸºæœ¬å¯¹åº”ï¼ˆASCIIï¼‰
    /// * âœ…åŸºæœ¬ä¿è¯ã€Œè§£æç»“æœå‡ä¿è¯ã€åˆæ³•ã€ã€
    /// * ğŸš©ã€2024-06-13 18:39:33ã€‘ç°åœ¨æ˜¯ã€Œè¯æ³•æŠ˜å ã€ä½¿ç”¨æœ¬å¤„å®ç°
    /// * âš ï¸åœ¨ã€Œè¯æ³•æŠ˜å ã€çš„è¿‡ç¨‹ä¸­ï¼Œå³å¼€å§‹ã€Œå˜é‡åŒ¿ååŒ–ã€
    ///   * ğŸ“Œã€2024-07-02 00:40:39ã€‘éœ€è¦ä¿è¯ã€Œæ ¼å¼åŒ–ã€çš„æ˜¯ä¸ªã€Œæ•´ä½“ã€ï¼šå˜é‡åªåœ¨ã€Œæ•´ä½“ã€èŒƒå›´å†…æœ‰æ„ä¹‰
    #[inline(always)]
    pub fn from_lexical(lexical: TermLexical) -> Result<Self> {
        fold_term(lexical, &mut vec![])
    }

    /// ä»ã€Œå†…éƒ¨Narseseã€è½¬æ¢ä¸ºã€Œè¯æ³•Narseseã€
    /// * ğŸš©åŸºæœ¬æ— æŸè½¬æ¢ï¼ˆæ— éœ€è€ƒè™‘å¤±è´¥æƒ…å†µï¼‰
    pub fn to_lexical(&self) -> TermLexical {
        use TermComponents::*;
        type LTerm = TermLexical;
        let (id, comp) = self.id_comp();
        match (id, comp) {
            // ä¸“ç”¨ / é›†åˆè¯é¡¹ | é»˜è®¤å·²æ’åº
            (SET_EXT_OPERATOR, Compound(v)) => {
                let v = v.iter().map(Self::to_lexical).collect::<Vec<_>>();
                LTerm::new_set(SET_EXT_OPENER, v, SET_EXT_CLOSER)
            }
            (SET_INT_OPERATOR, Compound(v)) => {
                let v = v.iter().map(Self::to_lexical).collect::<Vec<_>>();
                LTerm::new_set(SET_INT_OPENER, v, SET_INT_CLOSER)
            }
            //  é™ˆè¿°
            (
                INHERITANCE_RELATION | SIMILARITY_RELATION | IMPLICATION_RELATION
                | EQUIVALENCE_RELATION,
                Compound(terms),
            ) if terms.len() == 2 => {
                LTerm::new_statement(id, (&terms[0]).into(), (&terms[1]).into())
            }
            // é€šç”¨ / ç©ºï¼šä»…å‰ç¼€
            (_, Empty) => LTerm::new_atom(id, ""),
            // é€šç”¨ / å…·åï¼šå‰ç¼€+è¯é¡¹å
            (_, Word(name)) => LTerm::new_atom(id, name),
            // é€šç”¨ / å˜é‡ï¼šå‰ç¼€+å˜é‡ç¼–å·
            (_, Variable(num)) => LTerm::new_atom(id, num.to_string()),
            // é€šç”¨ / å¤šå…ƒ
            (_, Compound(terms)) => {
                LTerm::new_compound(id, terms.iter().map(Self::to_lexical).collect())
            }
        }
    }

    /// è½¬æ¢ä¸ºæ˜¾ç¤ºå‘ˆç°ä¸Šçš„ASCIIæ ¼å¼
    /// * ğŸ“Œå¯¹æ ‡OpenNARSçš„é»˜è®¤å‘ˆç°
    /// * âš ï¸ã€2024-07-02 00:52:54ã€‘ç›®å‰éœ€è¦ã€Œè¯æ³•Narseseã€ä½œä¸ºä¸­é—´æ ¼å¼ï¼Œå¯èƒ½ä¼šæœ‰æ€§èƒ½æŸå¤±
    pub fn to_display_ascii(&self) -> String {
        use narsese::conversion::string::impl_lexical::format_instances::FORMAT_ASCII;
        self.to_lexical().format_to(&FORMAT_ASCII)
    }

    /// å°è¯•ä»ã€Œæ–¹è¨€ã€è½¬æ¢
    /// * ğŸ¯æ”¯æŒã€Œæ–¹è¨€è§£æã€
    /// * ğŸ“Œã€2024-05-15 02:33:13ã€‘ç›®å‰ä»åªæœ‰ã€Œä»å­—ç¬¦ä¸²åˆ°è¯é¡¹ã€è¿™ä¸€ç§å½¢å¼
    /// * ğŸ†•é™„åŠ åŠŸèƒ½ï¼Œä¸æ ¸å¿ƒã€Œæ•°æ®ç®—æ³•ã€ã€Œæ¨ç†æ§åˆ¶ã€æ— å…³
    #[inline(always)]
    #[cfg(feature = "dialect_parser")]
    pub fn from_dialect(input: &str) -> Result<Self> {
        use super::super::dialect::parse_term;
        parse_term(input)
    }
}

// * ğŸš©æ­¤å¤„çš„ã€Œå˜é‡è¯é¡¹ã€ä¸€å¼€å§‹å°±åº”è¯¥æ˜¯ä¸ªæ•°å€¼ï¼Œä»ã€Œå…·åå˜é‡ã€å˜ä¸ºã€Œæ•°å­—å˜é‡ã€
/// è¯é¡¹â‡’è¯æ³•Narsese
impl From<&Term> for TermLexical {
    fn from(term: &Term) -> Self {
        term.to_lexical()
    }
}

impl From<TermComponents> for Vec<Term> {
    /// å°†ã€Œè¯é¡¹ç»„åˆ†ã€è½¬æ¢ä¸ºã€Œå¯å˜æ•°ç»„<è¯é¡¹>ã€
    /// * ğŸš©åŸå­è¯é¡¹â‡’ç©ºæ•°ç»„
    /// * ğŸš©å¤åˆè¯é¡¹â‡’å…¶å†…æ‰€æœ‰è¯é¡¹æ„æˆçš„æ•°ç»„
    fn from(value: TermComponents) -> Self {
        use TermComponents::*;
        match value {
            Empty | Word(..) | Variable(..) => vec![],
            Compound(terms) => terms.into(),
        }
    }
}

impl From<TermComponents> for Box<[Term]> {
    /// å°†ã€Œè¯é¡¹ç»„åˆ†ã€è½¬æ¢ä¸ºã€Œå®šé•¿æ•°ç»„<è¯é¡¹>ã€
    /// * ğŸš©åŸå­è¯é¡¹â‡’ç©ºæ•°ç»„
    /// * ğŸš©å¤åˆè¯é¡¹â‡’å…¶å†…æ‰€æœ‰è¯é¡¹æ„æˆçš„æ•°ç»„
    /// * â„¹ï¸ä¸ä¸Šè¿°å¯¹[`Vec`]çš„è½¬æ¢ä¸åŒï¼šæ­¤å¤„ç›´æ¥ä½¿ç”¨`Box::new([])`æ„é€ ç©ºæ•°ç»„
    fn from(value: TermComponents) -> Self {
        use TermComponents::*;
        match value {
            Empty | Word(..) | Variable(..) => Box::new([]),
            Compound(terms) => terms,
        }
    }
}

/// è¯æ³•æŠ˜å  / è·å–ã€Œæ ‡è¯†ç¬¦ã€
/// * ğŸ¯ä»ã€Œè¯æ³•Narseseã€è·å–ã€Œæ ‡è¯†ç¬¦ã€ï¼Œä»¥ä¾¿åç»­æ ¹æ®ã€Œæ ‡è¯†ç¬¦ã€åˆ†å‘é€»è¾‘
/// * ğŸš©å¯¹ã€Œé›†åˆã€è¯é¡¹ï¼šå°†å·¦å³æ‹¬å¼§ç›´æ¥æ‹¼æ¥ï¼Œä½œä¸ºæ–°çš„ã€ç»Ÿä¸€çš„ã€Œæ ‡è¯†ç¬¦ã€
fn get_identifier(term: &TermLexical) -> String {
    match term {
        TermLexical::Atom { prefix, .. } => prefix.clone(),
        TermLexical::Compound { connecter, .. } => connecter.clone(),
        TermLexical::Set {
            left_bracket,
            right_bracket,
            ..
        } => left_bracket.to_string() + right_bracket,
        TermLexical::Statement { copula, .. } => copula.clone(),
    }
}

/// æ ¹éƒ¨æŠ˜å ï¼ˆå¸¦ã€Œå˜é‡ç¼–å·åŒ–ã€é€»è¾‘ï¼‰
/// * ğŸš©æ¥å—åˆå§‹åŒ–åçš„æ•°ç»„
/// * â„¹ï¸å¯èƒ½è¢«é€’å½’è°ƒç”¨
fn fold_term(term: TermLexical, var_id_map: &mut Vec<String>) -> Result<Term> {
    /// æ›´æ–°å¹¶è¿”å›ä¸€ä¸ªã€Œå˜é‡è¯é¡¹ã€ï¼Œæ ¹æ®ä¼ å…¥çš„ã€Œå˜é‡idæ˜ å°„ã€å°†åŸã€Œå˜é‡åã€æ˜ å°„åˆ°ã€Œå˜é‡idã€
    #[inline]
    fn update_var(
        original_name: String,
        var_id_map: &mut Vec<String>,
        new_var_from_id: fn(usize) -> Term, // * ğŸ“ä¸ç”¨ç‰¹æ„å¼•ç”¨
    ) -> Term {
        match var_id_map
            .iter()
            .position(|stored_name| &original_name == stored_name)
        {
            // * ğŸš©idä»1å¼€å§‹
            Some(existed) => new_var_from_id(existed + 1),
            // * ğŸš©æ–°åç§°
            None => {
                var_id_map.push(original_name);
                new_var_from_id(var_id_map.len())
            }
        }
    }
    // æ­£å¼å¼€å§‹
    let identifier = get_identifier(&term);
    // åœ¨æœ‰é™çš„æ ‡è¯†ç¬¦èŒƒå›´å†…åŒ¹é…
    use TermLexical::*;
    let term = match (identifier.as_str(), term) {
        // åŸå­è¯é¡¹ | âš ï¸è™½ç„¶ã€Œå•ç‹¬çš„å ä½ç¬¦ã€åœ¨OpenNARSä¸­ä¸åˆæ³•ï¼Œä½†åœ¨è§£æã€Œåƒã€æ—¶éœ€è¦ç”¨åˆ° //
        (WORD, Atom { name, .. }) => Term::new_word(name),
        (PLACEHOLDER, Atom { .. }) => Term::new_placeholder(),
        (VAR_INDEPENDENT, Atom { name, .. }) => update_var(name, var_id_map, Term::new_var_i),
        (VAR_DEPENDENT, Atom { name, .. }) => update_var(name, var_id_map, Term::new_var_d),
        (VAR_QUERY, Atom { name, .. }) => update_var(name, var_id_map, Term::new_var_q),
        // å¤åˆè¯é¡¹ //
        (SET_EXT_OPERATOR, Set { terms, .. }) => {
            Term::new_set_ext(fold_lexical_terms(terms, var_id_map)?)
        }
        (SET_INT_OPERATOR, Set { terms, .. }) => {
            Term::new_set_int(fold_lexical_terms(terms, var_id_map)?)
        }
        (INTERSECTION_EXT_OPERATOR, Compound { terms, .. }) => {
            Term::new_intersection_ext(fold_lexical_terms(terms, var_id_map)?)
        }
        (INTERSECTION_INT_OPERATOR, Compound { terms, .. }) => {
            Term::new_intersection_int(fold_lexical_terms(terms, var_id_map)?)
        }
        (DIFFERENCE_EXT_OPERATOR, Compound { terms, .. }) if terms.len() == 2 => {
            let mut iter = terms.into_iter();
            let term1 = fold_term(iter.next().unwrap(), var_id_map)?;
            let term2 = fold_term(iter.next().unwrap(), var_id_map)?;
            Term::new_diff_ext(term1, term2)
        }
        (DIFFERENCE_INT_OPERATOR, Compound { terms, .. }) if terms.len() == 2 => {
            let mut iter = terms.into_iter();
            let term1 = fold_term(iter.next().unwrap(), var_id_map)?;
            let term2 = fold_term(iter.next().unwrap(), var_id_map)?;
            Term::new_diff_int(term1, term2)
        }
        (PRODUCT_OPERATOR, Compound { terms, .. }) => {
            Term::new_product(fold_lexical_terms(terms, var_id_map)?)
        }
        (IMAGE_EXT_OPERATOR, Compound { terms, .. }) => {
            // ! âš ï¸ç°åœ¨è§£æå‡ºä½œä¸ºã€Œåƒä¹‹å†…å®¹ã€çš„ã€Œè¯é¡¹åºåˆ—ã€åŒ…å«ã€Œå ä½ç¬¦ã€ä½œä¸ºå†…å®¹
            let (i, terms) = fold_lexical_terms_as_image(terms, var_id_map)?;
            match i {
                // å ä½ç¬¦åœ¨é¦–ä½â‡’è§†ä½œã€Œä¹˜ç§¯ã€ | ğŸ“NAL-4ä¸­ä¿ç•™ã€Œç¬¬0ä½ã€ä½œã€Œå…³ç³»ã€è¯é¡¹
                0 => Term::new_product(terms),
                _ => Term::new_image_ext(terms)?,
            }
        }
        (IMAGE_INT_OPERATOR, Compound { terms, .. }) => {
            // ! âš ï¸ç°åœ¨è§£æå‡ºä½œä¸ºã€Œåƒä¹‹å†…å®¹ã€çš„ã€Œè¯é¡¹åºåˆ—ã€åŒ…å«ã€Œå ä½ç¬¦ã€ä½œä¸ºå†…å®¹
            let (i, terms) = fold_lexical_terms_as_image(terms, var_id_map)?;
            match i {
                // å ä½ç¬¦åœ¨é¦–ä½â‡’è§†ä½œã€Œä¹˜ç§¯ã€ | ğŸ“NAL-4ä¸­ä¿ç•™ã€Œç¬¬0ä½ã€ä½œã€Œå…³ç³»ã€è¯é¡¹
                0 => Term::new_product(terms),
                _ => Term::new_image_int(terms)?,
            }
        }
        (CONJUNCTION_OPERATOR, Compound { terms, .. }) => {
            Term::new_conjunction(fold_lexical_terms(terms, var_id_map)?)
        }
        (DISJUNCTION_OPERATOR, Compound { terms, .. }) => {
            Term::new_disjunction(fold_lexical_terms(terms, var_id_map)?)
        }
        (NEGATION_OPERATOR, Compound { terms, .. }) if terms.len() == 1 => {
            let inner = fold_term(terms.into_iter().next().unwrap(), var_id_map)?;
            Term::new_negation(inner)
        }
        // é™ˆè¿°
        (
            INHERITANCE_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_inheritance(
            fold_term(*subject, var_id_map)?,
            fold_term(*predicate, var_id_map)?,
        ),
        (
            SIMILARITY_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_similarity(
            fold_term(*subject, var_id_map)?,
            fold_term(*predicate, var_id_map)?,
        ),
        (
            IMPLICATION_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_implication(
            fold_term(*subject, var_id_map)?,
            fold_term(*predicate, var_id_map)?,
        ),
        (
            EQUIVALENCE_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_equivalence(
            fold_term(*subject, var_id_map)?,
            fold_term(*predicate, var_id_map)?,
        ),
        (
            INSTANCE_RELATION, // æ´¾ç”Ÿç³»è¯/å®ä¾‹
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_inheritance(
            Term::new_set_ext(vec![fold_term(*subject, var_id_map)?]),
            fold_term(*predicate, var_id_map)?,
        ),
        (
            PROPERTY_RELATION, // æ´¾ç”Ÿç³»è¯/å±æ€§
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_inheritance(
            fold_term(*subject, var_id_map)?,
            Term::new_set_int(vec![fold_term(*predicate, var_id_map)?]),
        ),
        (
            INSTANCE_PROPERTY_RELATION, // æ´¾ç”Ÿç³»è¯/å®ä¾‹å±æ€§
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_inheritance(
            Term::new_set_ext(vec![fold_term(*subject, var_id_map)?]),
            Term::new_set_int(vec![fold_term(*predicate, var_id_map)?]),
        ),
        // å…¶å®ƒæƒ…å†µâ‡’ä¸åˆæ³•
        (identifier, this) => return Err(anyhow!("æ ‡è¯†ç¬¦ä¸ºã€Œ{identifier}ã€çš„éæ³•è¯é¡¹ï¼š{this:?}")),
    };
    Ok(term)
}

/// è¯æ³•æŠ˜å  / ä»ã€Œæ•°ç»„ã€ä¸­è½¬æ¢
/// * ğŸ¯å°†ã€Œè¯æ³•Narseseè¯é¡¹æ•°ç»„ã€è½¬æ¢ä¸ºã€Œå†…éƒ¨è¯é¡¹æ•°ç»„ã€
/// * ğŸ“Œåœ¨ã€Œæ— æ³•åŒæ—¶`map`ä¸`?`ã€æ—¶ç‹¬ç«‹æˆå‡½æ•°
/// * âš ï¸ä¸å…è®¸æ„é€ ç©ºè¯é¡¹æ•°ç»„ï¼šå‚è€ƒNALï¼Œä¸å…è®¸ç©ºé›†
#[inline]
fn fold_lexical_terms(terms: Vec<TermLexical>, var_id_map: &mut Vec<String>) -> Result<Vec<Term>> {
    let mut v = vec![];
    for term in terms {
        v.push(fold_term(term, var_id_map)?);
    }
    check_folded_terms(v)
}

/// æ£€æŸ¥æŠ˜å å¥½äº†çš„è¯é¡¹è¡¨
/// * ğŸš©ã€2024-06-14 00:13:29ã€‘ç›®å‰ä»…æ£€æŸ¥ã€Œæ˜¯å¦ä¸ºç©ºé›†ã€
fn check_folded_terms(v: Vec<Term>) -> Result<Vec<Term>> {
    match v.is_empty() {
        true => Err(anyhow!("è¯æ³•æŠ˜å é”™è¯¯ï¼šNALä¸å…è®¸æ„é€ ç©ºé›†")),
        false => Ok(v),
    }
}

/// è¯æ³•æŠ˜å  / ä»ã€Œæ•°ç»„ã€ä¸­è½¬æ¢æˆã€Œåƒã€
/// * ğŸ¯å°†ã€Œè¯æ³•Narseseè¯é¡¹æ•°ç»„ã€è½¬æ¢ä¸ºã€Œåƒã€æ‰€éœ€çš„ã€Œå¸¦ç´¢å¼•è¯é¡¹æ•°ç»„ã€
#[inline]
fn fold_lexical_terms_as_image(
    terms: Vec<TermLexical>,
    var_id_map: &mut Vec<String>,
) -> Result<(usize, Vec<Term>)> {
    // æ„é€ ã€Œç»„åˆ†ã€
    let mut v = vec![];
    let mut placeholder_index = 0;
    for (i, term) in terms.into_iter().enumerate() {
        let term: Term = fold_term(term, var_id_map)?;
        // è¯†åˆ«ã€Œå ä½ç¬¦ä½ç½®ã€
        // ğŸ†•ã€2024-04-21 01:12:50ã€‘ä¸åŒäºOpenNARSï¼šåªä¼šç•™ä¸‹ï¼ˆä¸”ä½ç½®å–å†³äºï¼‰æœ€åä¸€ä¸ªå ä½ç¬¦
        // ğŸ“„OpenNARSåœ¨ã€Œæ²¡æ‰¾åˆ°å ä½ç¬¦ã€æ—¶ï¼Œä¼šå°†ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºå ä½ç¬¦ï¼Œç„¶åæŠŠã€Œå ä½ç¬¦ç´¢å¼•ã€å›ºå®šä¸º`1`
        match term.is_placeholder() {
            true => {
                placeholder_index = i;
                if i > 0 {
                    // * ğŸš©å ä½ç¬¦ä¸èƒ½æ˜¯ç¬¬ä¸€ä¸ªâ‡’å¦åˆ™ä½œä¸ºã€Œä¹˜ç§¯ã€æäº¤ï¼ˆä¸åŒ…å«å ä½ç¬¦ï¼‰
                    v.push(term);
                }
            }
            // * ğŸš©ç°åœ¨é™¤äº†ã€Œå ä½ç¬¦åœ¨ç¬¬ä¸€ä¸ªã€ï¼ˆä¹˜ç§¯ï¼‰çš„æƒ…å½¢ï¼Œå…¶å®ƒå‡å°†ã€Œå ä½ç¬¦ã€ç®—å…¥åœ¨ã€Œå…ƒç´ ã€ä¸­
            false => v.push(term),
        }
    }
    Ok((placeholder_index, check_folded_terms(v)?))
}

/// è¯æ³•æŠ˜å 
impl TryFoldInto<'_, Term, anyhow::Error> for TermLexical {
    type Folder = ();

    fn try_fold_into(self, _: &'_ Self::Folder) -> Result<Term> {
        Term::from_lexical(self)
    }
}

/// åŸºäºã€Œè¯æ³•æŠ˜å ã€å®ç°[`TryFrom`]
impl TryFrom<TermLexical> for Term {
    type Error = anyhow::Error;

    #[inline(always)]
    fn try_from(value: TermLexical) -> Result<Self, Self::Error> {
        value.try_fold_into(&())
    }
}

/// å­—ç¬¦ä¸²è§£æè·¯çº¿ï¼šè¯æ³•è§£æ â‡’ è¯æ³•æŠ˜å 
/// * ğŸ¯åŒæ—¶å…¼å®¹[`str::parse`]ä¸[`str::try_into`]
/// * ğŸ“Œä½¿ç”¨æ ‡å‡†OpenNARS ASCIIè¯­æ³•
impl TryFrom<&str> for Term {
    type Error = anyhow::Error;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        use narsese::conversion::string::impl_lexical::format_instances::FORMAT_ASCII;
        // è¯æ³•è§£æ
        let lexical = FORMAT_ASCII.parse(s)?;
        // è¯æ³•è½¬æ¢ | âš ï¸å¯¹ã€Œè¯­å¥ã€ã€Œä»»åŠ¡ã€æŠ¥é”™
        let term = lexical.try_into_term()?;
        // è¯æ³•æŠ˜å 
        let term = term.try_into()?;
        // è¿”å›
        Ok(term)
    }
}

///  å­—ç¬¦ä¸²è§£æ
/// * ğŸ¯åŒæ—¶å…¼å®¹[`str::parse`]ä¸[`str::try_into`]
impl FromStr for Term {
    type Err = anyhow::Error;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        s.try_into()
    }
}

/// å•å…ƒæµ‹è¯•
#[cfg(test)]
mod tests {
    use super::*;
    use crate::{ok, util::AResult};
    use narsese::{
        conversion::{
            inter_type::lexical_fold::TryFoldInto,
            string::impl_lexical::format_instances::FORMAT_ASCII,
        },
        lexical::Term as LexicalTerm,
        lexical_nse_term,
    };

    /// æµ‹è¯• / è¯æ³•æŠ˜å 
    #[test]
    fn test_lexical_fold() -> AResult {
        fn fold(t: LexicalTerm) -> Result<Term> {
            print!("{:?} => ", FORMAT_ASCII.format(&t));
            let term: Term = t.try_fold_into(&())?;
            println!("{:?}", term.format_name());
            Ok(term)
        }
        fold(lexical_nse_term!(<A --> B>))?;
        fold(lexical_nse_term!((&&, C, B, A, (/, A, _, B))))?;
        // fold(lexical_nse_term!(<(*, {SELF}, x, y) --> ^left>))?; // ! âš ï¸ã€2024-04-25 10:02:20ã€‘ç°åœ¨å¯¹ã€Œæ“ä½œç¬¦ã€ä¸å†æ”¯æŒ
        fold(lexical_nse_term!([2, 1, 0, $0, #1, ?2]))?;
        fold(lexical_nse_term!(<A <-> {A}>))?;
        fold(lexical_nse_term!(<{B} <=> B>))?;
        fold(lexical_nse_term!(<{SELF} ==> (--, [good])>))?;
        ok!()
    }

    /// æµ‹è¯• / å˜é‡é‡ç¼–å·
    /// * ğŸ“„nse  `<(&&,<(*,{$1},{$2},$d)-->æ–¹å‘>,<(*,{$1},$c)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$2},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>)==><(*,$d,$c,{$1},{$2})-->[åŒè‰²è¿ç©º]>>.%1.00;0.99%`
    ///   * ğŸ•’ã€2024-07-02 00:32:46ã€‘
    ///   * é¢„æœŸï¼š`<(&&,<(*,{$1},{$2},$3)-->æ–¹å‘>,<(*,{$1},$4)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$2},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>)==><(*,$3,$4,{$1},{$2})-->[åŒè‰²è¿ç©º]>>. %1.0;0.99%`
    ///   * å½“å‰ï¼š`<(&&,<(*,{$1},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$1},$2)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$1},{$2},$3)-->æ–¹å‘>)==><(*,$1,$2,{$3},{$4})-->[åŒè‰²è¿ç©º]>>.%1.0000;0.9900%`
    ///   * é¢„æœŸã®æ˜ å°„ï¼š
    ///     * `$1` => `$1`
    ///     * `$2` => `$2`
    ///     * `$d` => `$3`
    ///     * `$c` => `$4`
    ///   * å½“å‰ã®æ˜ å°„ï¼š
    ///     * `$1` => `$1`
    ///     * `$2` => `$2`ã€`$1`@ã€Œæ— ç¼ºé™·ã€
    ///     * `$d` => `$3`ã€`$1`@åŒè‰²è¿ç©º
    ///     * `$c` => `$2`
    /// * âœ…ã€2024-07-02 01:06:12ã€‘ç°åœ¨æˆåŠŸï¼šè‡³å°‘æ˜¯å”¯ä¸€æ˜ å°„äº†
    ///     * `$1` => `$1`
    ///     * `$2` => `$2`
    ///     * `$d` => `$4`
    ///     * `$c` => `$3`
    #[test]
    fn test_var_map() -> AResult {
        // è¯æ³•Narseseå±•ç¤º
        let lexical = lexical_nse_term!(<(&&,<(*,{$1},{$2},$d)-->æ–¹å‘>,<(*,{$1},$c)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$2},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>)==><(*,$d,$c,{$1},{$2})-->[åŒè‰²è¿ç©º]>>);
        println!("{}", FORMAT_ASCII.format(&lexical));

        // è¯æ³•æŠ˜å 
        let term1 = Term::from_lexical(lexical.clone())?;
        let term1_s = term1.to_display_ascii();
        println!("{term1_s}");

        // å†…éƒ¨æŠ˜å æ–¹æ³•
        let mut var_map = vec![];
        let term2 = fold_term(lexical.clone(), &mut var_map)?;
        let term2_s = term2.to_display_ascii();
        println!("{term2_s}");
        assert_eq!(term1_s, term2_s); // ä¸¤ç§è½¬æ¢ä¹‹åï¼Œå­—ç¬¦ä¸²å½¢å¼åº”è¯¥ç›¸ç­‰

        // å¯¹æ¯”ï¼šæ˜ å°„è¡¨
        println!("{:?}", var_map);
        for (var_i, original_name) in var_map.iter().enumerate() {
            println!("{original_name} => {}", var_i + 1);
        }
        let expected = [("1", 1), ("2", 2), ("d", 3), ("c", 4)];
        for (original_name, var_i) in expected.iter() {
            // æ–­è¨€æ˜ å°„è¡¨ç›¸ç­‰
            assert_eq!(var_map[*var_i - 1], *original_name);
        }
        ok!()
    }
}
