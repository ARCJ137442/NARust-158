//! ä¸å…¶å®ƒç±»å‹ç›¸äº’è½¬æ¢
//! * ğŸ¯è½¬æ¢ä¸ºã€Œè¯æ³•Narseseã€ä»¥ä¾¿ã€Œè·å–åç§°ã€

use super::structs::*;
use crate::io::symbols::*;
use anyhow::{anyhow, Result};
use nar_dev_utils::*;
use narsese::{
    api::GetCapacity,
    conversion::{
        inter_type::lexical_fold::TryFoldInto, string::impl_lexical::format_instances::FORMAT_ASCII,
    },
    lexical::Term as TermLexical,
};
use std::str::FromStr;

/// è¯é¡¹â‡’å­—ç¬¦ä¸²
/// * ğŸ¯ç”¨äºæ›´å¥½åœ°æ‰“å°ã€Œè¯é¡¹ã€åç§°
/// * ğŸ¯ç”¨äºä»ã€Œè¯æ³•Narseseã€ä¸­è§£æ
///   * è€ƒè™‘ã€Œå˜é‡è¯­ä¹‰ã€
impl Term {
    pub fn format_name(&self) -> String {
        // æ ¼å¼åŒ–æ‰€ç”¨å¸¸é‡
        const OPENER: &str = "(";
        const CLOSER: &str = ")";
        const SEPARATOR: &str = " ";

        use narsese::api::TermCapacity::*;
        use TermComponents::*;
        let id = &self.identifier;
        match &self.components {
            // ç©ºç»„åˆ†
            Empty => id.clone(),
            // åç§° | åŸå­è¯é¡¹
            Word(name) => id.clone() + name,
            // åç§° | å˜é‡è¯é¡¹
            Variable(n) => id.clone() + &n.to_string(),
            Compound(terms) => {
                match self.get_capacity() {
                    // ä¸€å…ƒ
                    Unary => {
                        // ğŸ“„ "(-- A)"
                        manipulate!(
                            String::new()
                            => {+= OPENER}#
                            => {+= id}#
                            => {+= SEPARATOR}#
                            => {+= &terms[0].format_name()}#
                            => {+= CLOSER}#
                        )
                    }
                    // äºŒå…ƒ
                    BinaryVec | BinarySet => {
                        // ğŸ“„ "(A --> B)"
                        manipulate!(
                            String::new()
                            => {+= OPENER}#
                            => {+= &terms[0].format_name()}#
                            => {+= SEPARATOR}#
                            => {+= id}#
                            => {+= SEPARATOR}#
                            => {+= &terms[1].format_name()}#
                            => {+= CLOSER}#
                        )
                    }
                    // å¤šå…ƒ
                    Vec | Set => {
                        let mut s = id.to_string() + OPENER;
                        let mut terms = terms.iter();
                        if let Some(t) = terms.next() {
                            s += &t.format_name();
                        }
                        for t in terms {
                            s += SEPARATOR;
                            s += &t.format_name();
                        }
                        s + CLOSER
                    }
                    Atom => unreachable!("å¤åˆè¯é¡¹åªå¯èƒ½æ˜¯ã€Œä¸€å…ƒã€ã€ŒäºŒå…ƒã€æˆ–ã€Œå¤šå…ƒã€"),
                }
            }
        }
    }

    /// å°è¯•ä»ã€Œè¯æ³•Narseseã€è½¬æ¢
    /// * ğŸ’­ã€2024-04-21 14:44:15ã€‘ç›®å‰æ­¤ä¸­æ–¹æ³•ã€Œç›¸è¾ƒä¿å®ˆã€
    /// * ğŸ“Œä¸è¯æ³•NarseseåŸºæœ¬å¯¹åº”ï¼ˆASCIIï¼‰
    /// * âœ…åŸºæœ¬ä¿è¯ã€Œè§£æç»“æœå‡ä¿è¯ã€åˆæ³•ã€ã€
    /// * ğŸš©ã€2024-06-13 18:39:33ã€‘ç°åœ¨æ˜¯ã€Œè¯æ³•æŠ˜å ã€ä½¿ç”¨æœ¬å¤„å®ç°
    /// * âš ï¸åœ¨ã€Œè¯æ³•æŠ˜å ã€çš„è¿‡ç¨‹ä¸­ï¼Œå³å¼€å§‹ã€Œå˜é‡åŒ¿ååŒ–ã€
    #[inline(always)]
    pub fn from_lexical(lexical: TermLexical) -> Result<Self> {
        fold_term(lexical, &mut vec![])
    }

    /// å°è¯•ä»ã€Œæ–¹è¨€ã€è½¬æ¢
    /// * ğŸ¯æ”¯æŒã€Œæ–¹è¨€è§£æã€
    /// * ğŸ“Œã€2024-05-15 02:33:13ã€‘ç›®å‰ä»åªæœ‰ã€Œä»å­—ç¬¦ä¸²åˆ°è¯é¡¹ã€è¿™ä¸€ç§å½¢å¼
    /// * ğŸ†•é™„åŠ åŠŸèƒ½ï¼Œä¸æ ¸å¿ƒã€Œæ•°æ®ç®—æ³•ã€ã€Œæ¨ç†æ§åˆ¶ã€æ— å…³
    #[inline(always)]
    #[cfg(feature = "dialect_parser")]
    pub fn from_dialect(input: &str) -> Result<Self> {
        use super::super::dialect::parse_term;
        parse_term(input)
    }
}

// * ğŸš©æ­¤å¤„çš„ã€Œå˜é‡è¯é¡¹ã€ä¸€å¼€å§‹å°±åº”è¯¥æ˜¯ä¸ªæ•°å€¼ï¼Œä»ã€Œå…·åå˜é‡ã€å˜ä¸ºã€Œæ•°å­—å˜é‡ã€
/// è¯é¡¹â‡’è¯æ³•Narsese
impl From<&Term> for TermLexical {
    fn from(value: &Term) -> Self {
        use TermComponents::*;
        let (id, comp) = value.id_comp();
        match (id, comp) {
            // ä¸“ç”¨ / é›†åˆè¯é¡¹ | é»˜è®¤å·²æ’åº
            (SET_EXT_OPERATOR, Compound(v)) => {
                let v = v.iter().map(TermLexical::from).collect::<Vec<_>>();
                Self::new_set(SET_EXT_OPENER, v, SET_EXT_CLOSER)
            }
            (SET_INT_OPERATOR, Compound(v)) => {
                let v = v.iter().map(TermLexical::from).collect::<Vec<_>>();
                Self::new_set(SET_INT_OPENER, v, SET_INT_CLOSER)
            }
            //  é™ˆè¿°
            (
                INHERITANCE_RELATION | SIMILARITY_RELATION | IMPLICATION_RELATION
                | EQUIVALENCE_RELATION,
                Compound(terms),
            ) if terms.len() == 2 => {
                Self::new_statement(id, (&terms[0]).into(), (&terms[1]).into())
            }
            // é€šç”¨ / ç©ºï¼šä»…å‰ç¼€
            (_, Empty) => Self::new_atom(id, ""),
            // é€šç”¨ / å…·åï¼šå‰ç¼€+è¯é¡¹å
            (_, Word(name)) => Self::new_atom(id, name),
            // é€šç”¨ / å˜é‡ï¼šå‰ç¼€+å˜é‡ç¼–å·
            (_, Variable(num)) => Self::new_atom(id, num.to_string()),
            // é€šç”¨ / å¤šå…ƒ
            (_, Compound(terms)) => {
                Self::new_compound(id, terms.iter().map(TermLexical::from).collect())
            }
        }
    }
}

impl From<TermComponents> for Vec<Term> {
    /// å°†ã€Œè¯é¡¹ç»„åˆ†ã€è½¬æ¢ä¸ºã€Œå¯å˜æ•°ç»„<è¯é¡¹>ã€
    /// * ğŸš©åŸå­è¯é¡¹â‡’ç©ºæ•°ç»„
    /// * ğŸš©å¤åˆè¯é¡¹â‡’å…¶å†…æ‰€æœ‰è¯é¡¹æ„æˆçš„æ•°ç»„
    fn from(value: TermComponents) -> Self {
        use TermComponents::*;
        match value {
            Empty | Word(..) | Variable(..) => vec![],
            Compound(terms) => terms.into(),
        }
    }
}

impl From<TermComponents> for Box<[Term]> {
    /// å°†ã€Œè¯é¡¹ç»„åˆ†ã€è½¬æ¢ä¸ºã€Œå®šé•¿æ•°ç»„<è¯é¡¹>ã€
    /// * ğŸš©åŸå­è¯é¡¹â‡’ç©ºæ•°ç»„
    /// * ğŸš©å¤åˆè¯é¡¹â‡’å…¶å†…æ‰€æœ‰è¯é¡¹æ„æˆçš„æ•°ç»„
    /// * â„¹ï¸ä¸ä¸Šè¿°å¯¹[`Vec`]çš„è½¬æ¢ä¸åŒï¼šæ­¤å¤„ç›´æ¥ä½¿ç”¨`Box::new([])`æ„é€ ç©ºæ•°ç»„
    fn from(value: TermComponents) -> Self {
        use TermComponents::*;
        match value {
            Empty | Word(..) | Variable(..) => Box::new([]),
            Compound(terms) => terms,
        }
    }
}

/// è¯æ³•æŠ˜å  / è·å–ã€Œæ ‡è¯†ç¬¦ã€
/// * ğŸ¯ä»ã€Œè¯æ³•Narseseã€è·å–ã€Œæ ‡è¯†ç¬¦ã€ï¼Œä»¥ä¾¿åç»­æ ¹æ®ã€Œæ ‡è¯†ç¬¦ã€åˆ†å‘é€»è¾‘
/// * ğŸš©å¯¹ã€Œé›†åˆã€è¯é¡¹ï¼šå°†å·¦å³æ‹¬å¼§ç›´æ¥æ‹¼æ¥ï¼Œä½œä¸ºæ–°çš„ã€ç»Ÿä¸€çš„ã€Œæ ‡è¯†ç¬¦ã€
fn get_identifier(term: &TermLexical) -> String {
    match term {
        TermLexical::Atom { prefix, .. } => prefix.clone(),
        TermLexical::Compound { connecter, .. } => connecter.clone(),
        TermLexical::Set {
            left_bracket,
            right_bracket,
            ..
        } => left_bracket.to_string() + right_bracket,
        TermLexical::Statement { copula, .. } => copula.clone(),
    }
}

/// æ ¹éƒ¨æŠ˜å ï¼ˆå¸¦ã€Œå˜é‡ç¼–å·åŒ–ã€é€»è¾‘ï¼‰
/// * ğŸš©æ¥å—åˆå§‹åŒ–åçš„æ•°ç»„
/// * â„¹ï¸å¯èƒ½è¢«é€’å½’è°ƒç”¨
fn fold_term(term: TermLexical, var_id_map: &mut Vec<String>) -> Result<Term> {
    /// æ›´æ–°å¹¶è¿”å›ä¸€ä¸ªã€Œå˜é‡è¯é¡¹ã€ï¼Œæ ¹æ®ä¼ å…¥çš„ã€Œå˜é‡idæ˜ å°„ã€å°†åŸã€Œå˜é‡åã€æ˜ å°„åˆ°ã€Œå˜é‡idã€
    #[inline]
    fn update_var(
        original_name: String,
        var_id_map: &mut Vec<String>,
        new_var_from_id: fn(usize) -> Term, // * ğŸ“ä¸ç”¨ç‰¹æ„å¼•ç”¨
    ) -> Term {
        match var_id_map
            .iter()
            .position(|stored_name| &original_name == stored_name)
        {
            // * ğŸš©idä»1å¼€å§‹
            Some(existed) => new_var_from_id(existed + 1),
            // * ğŸš©æ–°åç§°
            None => {
                var_id_map.push(original_name);
                new_var_from_id(var_id_map.len())
            }
        }
    }
    let identifier = get_identifier(&term);
    let self_str = FORMAT_ASCII.format(&term);
    // åœ¨æœ‰é™çš„æ ‡è¯†ç¬¦èŒƒå›´å†…åŒ¹é…
    use TermLexical::*;
    let term = match (identifier.as_str(), term) {
        // åŸå­è¯é¡¹ | âš ï¸è™½ç„¶ã€Œå•ç‹¬çš„å ä½ç¬¦ã€åœ¨OpenNARSä¸­ä¸åˆæ³•ï¼Œä½†åœ¨è§£æã€Œåƒã€æ—¶éœ€è¦ç”¨åˆ° //
        (WORD, Atom { name, .. }) => Term::new_word(name),
        (PLACEHOLDER, Atom { .. }) => Term::new_placeholder(),
        (VAR_INDEPENDENT, Atom { name, .. }) => update_var(name, var_id_map, Term::new_var_i),
        (VAR_DEPENDENT, Atom { name, .. }) => update_var(name, var_id_map, Term::new_var_d),
        (VAR_QUERY, Atom { name, .. }) => update_var(name, var_id_map, Term::new_var_q),
        // å¤åˆè¯é¡¹ //
        (SET_EXT_OPERATOR, Set { terms, .. }) => {
            Term::new_set_ext(fold_lexical_terms(terms, var_id_map)?)
        }
        (SET_INT_OPERATOR, Set { terms, .. }) => {
            Term::new_set_int(fold_lexical_terms(terms, var_id_map)?)
        }
        (INTERSECTION_EXT_OPERATOR, Compound { terms, .. }) => {
            Term::new_intersection_ext(fold_lexical_terms(terms, var_id_map)?)
        }
        (INTERSECTION_INT_OPERATOR, Compound { terms, .. }) => {
            Term::new_intersection_int(fold_lexical_terms(terms, var_id_map)?)
        }
        (DIFFERENCE_EXT_OPERATOR, Compound { terms, .. }) if terms.len() == 2 => {
            let mut iter = terms.into_iter();
            let term1 = iter.next().unwrap().try_into()?;
            let term2 = iter.next().unwrap().try_into()?;
            Term::new_diff_ext(term1, term2)
        }
        (DIFFERENCE_INT_OPERATOR, Compound { terms, .. }) if terms.len() == 2 => {
            let mut iter = terms.into_iter();
            let term1 = iter.next().unwrap().try_into()?;
            let term2 = iter.next().unwrap().try_into()?;
            Term::new_diff_int(term1, term2)
        }
        (PRODUCT_OPERATOR, Compound { terms, .. }) => {
            Term::new_product(fold_lexical_terms(terms, var_id_map)?)
        }
        (IMAGE_EXT_OPERATOR, Compound { terms, .. }) => {
            // ! âš ï¸ç°åœ¨è§£æå‡ºä½œä¸ºã€Œåƒä¹‹å†…å®¹ã€çš„ã€Œè¯é¡¹åºåˆ—ã€åŒ…å«ã€Œå ä½ç¬¦ã€ä½œä¸ºå†…å®¹
            let (i, terms) = fold_lexical_terms_as_image(terms, var_id_map)?;
            match i {
                // å ä½ç¬¦åœ¨é¦–ä½â‡’è§†ä½œã€Œä¹˜ç§¯ã€ | ğŸ“NAL-4ä¸­ä¿ç•™ã€Œç¬¬0ä½ã€ä½œã€Œå…³ç³»ã€è¯é¡¹
                0 => Term::new_product(terms),
                _ => Term::new_image_ext(terms)?,
            }
        }
        (IMAGE_INT_OPERATOR, Compound { terms, .. }) => {
            // ! âš ï¸ç°åœ¨è§£æå‡ºä½œä¸ºã€Œåƒä¹‹å†…å®¹ã€çš„ã€Œè¯é¡¹åºåˆ—ã€åŒ…å«ã€Œå ä½ç¬¦ã€ä½œä¸ºå†…å®¹
            let (i, terms) = fold_lexical_terms_as_image(terms, var_id_map)?;
            match i {
                // å ä½ç¬¦åœ¨é¦–ä½â‡’è§†ä½œã€Œä¹˜ç§¯ã€ | ğŸ“NAL-4ä¸­ä¿ç•™ã€Œç¬¬0ä½ã€ä½œã€Œå…³ç³»ã€è¯é¡¹
                0 => Term::new_product(terms),
                _ => Term::new_image_int(terms)?,
            }
        }
        (CONJUNCTION_OPERATOR, Compound { terms, .. }) => {
            Term::new_conjunction(fold_lexical_terms(terms, var_id_map)?)
        }
        (DISJUNCTION_OPERATOR, Compound { terms, .. }) => {
            Term::new_disjunction(fold_lexical_terms(terms, var_id_map)?)
        }
        (NEGATION_OPERATOR, Compound { terms, .. }) if terms.len() == 1 => {
            Term::new_negation(terms.into_iter().next().unwrap().try_into()?)
        }
        // é™ˆè¿°
        (
            INHERITANCE_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_inheritance(subject.try_fold_into(&())?, predicate.try_fold_into(&())?),
        (
            SIMILARITY_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_similarity(subject.try_fold_into(&())?, predicate.try_fold_into(&())?),
        (
            IMPLICATION_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_implication(subject.try_fold_into(&())?, predicate.try_fold_into(&())?),
        (
            EQUIVALENCE_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_equivalence(subject.try_fold_into(&())?, predicate.try_fold_into(&())?),
        (
            INSTANCE_RELATION, // æ´¾ç”Ÿç³»è¯/å®ä¾‹
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_inheritance(
            Term::new_set_ext(vec![subject.try_fold_into(&())?]),
            predicate.try_fold_into(&())?,
        ),

        (
            PROPERTY_RELATION, // æ´¾ç”Ÿç³»è¯/å±æ€§
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_inheritance(
            subject.try_fold_into(&())?,
            Term::new_set_int(vec![predicate.try_fold_into(&())?]),
        ),
        (
            INSTANCE_PROPERTY_RELATION, // æ´¾ç”Ÿç³»è¯/å®ä¾‹å±æ€§
            Statement {
                subject, predicate, ..
            },
        ) => Term::new_inheritance(
            Term::new_set_ext(vec![subject.try_fold_into(&())?]),
            Term::new_set_int(vec![predicate.try_fold_into(&())?]),
        ),
        // å…¶å®ƒæƒ…å†µâ‡’ä¸åˆæ³•
        _ => return Err(anyhow!("éæ³•è¯é¡¹ï¼š{self_str:?}")),
    };
    Ok(term)
}

/// è¯æ³•æŠ˜å  / ä»ã€Œæ•°ç»„ã€ä¸­è½¬æ¢
/// * ğŸ¯å°†ã€Œè¯æ³•Narseseè¯é¡¹æ•°ç»„ã€è½¬æ¢ä¸ºã€Œå†…éƒ¨è¯é¡¹æ•°ç»„ã€
/// * ğŸ“Œåœ¨ã€Œæ— æ³•åŒæ—¶`map`ä¸`?`ã€æ—¶ç‹¬ç«‹æˆå‡½æ•°
/// * âš ï¸ä¸å…è®¸æ„é€ ç©ºè¯é¡¹æ•°ç»„ï¼šå‚è€ƒNALï¼Œä¸å…è®¸ç©ºé›†
#[inline]
fn fold_lexical_terms(terms: Vec<TermLexical>, var_id_map: &mut Vec<String>) -> Result<Vec<Term>> {
    let mut v = vec![];
    for term in terms {
        v.push(fold_term(term, var_id_map)?);
    }
    check_folded_terms(v)
}

/// æ£€æŸ¥æŠ˜å å¥½äº†çš„è¯é¡¹è¡¨
/// * ğŸš©ã€2024-06-14 00:13:29ã€‘ç›®å‰ä»…æ£€æŸ¥ã€Œæ˜¯å¦ä¸ºç©ºé›†ã€
fn check_folded_terms(v: Vec<Term>) -> Result<Vec<Term>> {
    match v.is_empty() {
        true => Err(anyhow!("è¯æ³•æŠ˜å é”™è¯¯ï¼šNALä¸å…è®¸æ„é€ ç©ºé›†")),
        false => Ok(v),
    }
}

/// è¯æ³•æŠ˜å  / ä»ã€Œæ•°ç»„ã€ä¸­è½¬æ¢æˆã€Œåƒã€
/// * ğŸ¯å°†ã€Œè¯æ³•Narseseè¯é¡¹æ•°ç»„ã€è½¬æ¢ä¸ºã€Œåƒã€æ‰€éœ€çš„ã€Œå¸¦ç´¢å¼•è¯é¡¹æ•°ç»„ã€
#[inline]
fn fold_lexical_terms_as_image(
    terms: Vec<TermLexical>,
    var_id_map: &mut Vec<String>,
) -> Result<(usize, Vec<Term>)> {
    // æ„é€ ã€Œç»„åˆ†ã€
    let mut v = vec![];
    let mut placeholder_index = 0;
    for (i, term) in terms.into_iter().enumerate() {
        let term: Term = fold_term(term, var_id_map)?;
        // è¯†åˆ«ã€Œå ä½ç¬¦ä½ç½®ã€
        // ğŸ†•ã€2024-04-21 01:12:50ã€‘ä¸åŒäºOpenNARSï¼šåªä¼šç•™ä¸‹ï¼ˆä¸”ä½ç½®å–å†³äºï¼‰æœ€åä¸€ä¸ªå ä½ç¬¦
        // ğŸ“„OpenNARSåœ¨ã€Œæ²¡æ‰¾åˆ°å ä½ç¬¦ã€æ—¶ï¼Œä¼šå°†ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºå ä½ç¬¦ï¼Œç„¶åæŠŠã€Œå ä½ç¬¦ç´¢å¼•ã€å›ºå®šä¸º`1`
        match term.is_placeholder() {
            true => {
                placeholder_index = i;
                if i > 0 {
                    // * ğŸš©å ä½ç¬¦ä¸èƒ½æ˜¯ç¬¬ä¸€ä¸ªâ‡’å¦åˆ™ä½œä¸ºã€Œä¹˜ç§¯ã€æäº¤ï¼ˆä¸åŒ…å«å ä½ç¬¦ï¼‰
                    v.push(term);
                }
            }
            // * ğŸš©ç°åœ¨é™¤äº†ã€Œå ä½ç¬¦åœ¨ç¬¬ä¸€ä¸ªã€ï¼ˆä¹˜ç§¯ï¼‰çš„æƒ…å½¢ï¼Œå…¶å®ƒå‡å°†ã€Œå ä½ç¬¦ã€ç®—å…¥åœ¨ã€Œå…ƒç´ ã€ä¸­
            false => v.push(term),
        }
    }
    Ok((placeholder_index, check_folded_terms(v)?))
}

/// è¯æ³•æŠ˜å 
impl TryFoldInto<'_, Term, anyhow::Error> for TermLexical {
    type Folder = ();

    fn try_fold_into(self, _: &'_ Self::Folder) -> Result<Term> {
        Term::from_lexical(self)
    }
}

/// åŸºäºã€Œè¯æ³•æŠ˜å ã€å®ç°[`TryFrom`]
impl TryFrom<TermLexical> for Term {
    type Error = anyhow::Error;

    #[inline(always)]
    fn try_from(value: TermLexical) -> Result<Self, Self::Error> {
        value.try_fold_into(&())
    }
}

/// å­—ç¬¦ä¸²è§£æè·¯çº¿ï¼šè¯æ³•è§£æ â‡’ è¯æ³•æŠ˜å 
/// * ğŸ¯åŒæ—¶å…¼å®¹[`str::parse`]ä¸[`str::try_into`]
impl TryFrom<&str> for Term {
    type Error = anyhow::Error;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        // è¯æ³•è§£æ
        let lexical = FORMAT_ASCII.parse(s)?;
        // è¯æ³•è½¬æ¢ | âš ï¸å¯¹ã€Œè¯­å¥ã€ã€Œä»»åŠ¡ã€æŠ¥é”™
        let term = lexical.try_into_term()?;
        // è¯æ³•æŠ˜å 
        let term = term.try_into()?;
        // è¿”å›
        Ok(term)
    }
}

///  å­—ç¬¦ä¸²è§£æ
/// * ğŸ¯åŒæ—¶å…¼å®¹[`str::parse`]ä¸[`str::try_into`]
impl FromStr for Term {
    type Err = anyhow::Error;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        s.try_into()
    }
}

/// å•å…ƒæµ‹è¯•
#[cfg(test)]
mod tests {
    use super::*;
    use crate::{global::tests::AResult, ok};
    use narsese::{
        conversion::{
            inter_type::lexical_fold::TryFoldInto,
            string::impl_lexical::format_instances::FORMAT_ASCII,
        },
        lexical::Term as LexicalTerm,
        lexical_nse_term,
    };

    /// æµ‹è¯• / è¯æ³•æŠ˜å 
    #[test]
    fn test_lexical_fold() -> AResult {
        fn fold(t: LexicalTerm) -> Result<Term> {
            print!("{:?} => ", FORMAT_ASCII.format(&t));
            let term: Term = t.try_fold_into(&())?;
            println!("{:?}", term.format_name());
            Ok(term)
        }
        fold(lexical_nse_term!(<A --> B>))?;
        fold(lexical_nse_term!((&&, C, B, A, (/, A, _, B))))?;
        // fold(lexical_nse_term!(<(*, {SELF}, x, y) --> ^left>))?; // ! âš ï¸ã€2024-04-25 10:02:20ã€‘ç°åœ¨å¯¹ã€Œæ“ä½œç¬¦ã€ä¸å†æ”¯æŒ
        fold(lexical_nse_term!([2, 1, 0, $0, #1, ?2]))?;
        fold(lexical_nse_term!(<A <-> {A}>))?;
        fold(lexical_nse_term!(<{B} <=> B>))?;
        fold(lexical_nse_term!(<{SELF} ==> (--, [good])>))?;
        ok!()
    }
}
