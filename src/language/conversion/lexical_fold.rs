//! ç®¡ç†æœ‰å…³Narseseè¯é¡¹ã€Œè¯æ³•æŠ˜å ã€çš„åŠŸèƒ½
//! * ğŸ¯å®ç°ã€Œè¯æ³•Narseseâ†’å†…éƒ¨Narseseã€çš„è½¬æ¢
//!   * âš ï¸å­˜åœ¨ã€Œè¯­ä¹‰æ— æ•ˆã€çš„æƒ…å†µ
//!     * ğŸ“„åœ¨NALä¹‹å¤–çš„è¯é¡¹ç±»å‹
//!     * ğŸ“„ç©ºé›†ã€é‡è¨€å¼ç­‰ã€Œè¯­ä¹‰æ— æ•ˆã€è¯é¡¹

use super::super::base::*;
use crate::symbols::*;
use anyhow::{anyhow, Result};
use narsese::lexical::Term as TermLexical;

/// è¯æ³•æŠ˜å  / è·å–ã€Œæ ‡è¯†ç¬¦ã€
/// * ğŸ¯ä»ã€Œè¯æ³•Narseseã€è·å–ã€Œæ ‡è¯†ç¬¦ã€ï¼Œä»¥ä¾¿åç»­æ ¹æ®ã€Œæ ‡è¯†ç¬¦ã€åˆ†å‘é€»è¾‘
/// * ğŸš©å¯¹ã€Œé›†åˆã€è¯é¡¹ï¼šå°†å·¦å³æ‹¬å¼§ç›´æ¥æ‹¼æ¥ï¼Œä½œä¸ºæ–°çš„ã€ç»Ÿä¸€çš„ã€Œæ ‡è¯†ç¬¦ã€
fn get_identifier(term: &TermLexical) -> String {
    match term {
        TermLexical::Atom { prefix, .. } => prefix.clone(),
        TermLexical::Compound { connecter, .. } => connecter.clone(),
        TermLexical::Set {
            left_bracket,
            right_bracket,
            ..
        } => left_bracket.to_string() + right_bracket,
        TermLexical::Statement { copula, .. } => copula.clone(),
    }
}

/// è¯æ³•æŠ˜å çš„ä¸Šä¸‹æ–‡å¯¹è±¡
/// * ğŸ¯ç»Ÿä¸€å­˜å‚¨å¦‚ã€Œå˜é‡idæ˜ å°„ã€çš„ä¸´æ—¶çŠ¶æ€
#[derive(Debug, Clone)]
struct FoldContext {
    /// æœ‰å…³ã€Œå˜é‡idâ‡’è¯é¡¹åç§°ã€çš„æ˜ å°„
    var_id_map: Vec<String>,
}

impl FoldContext {
    /// åˆ›å»ºä¸€ä¸ªæ–°çš„ä¸Šä¸‹æ–‡
    fn new() -> Self {
        Self { var_id_map: vec![] }
    }
}

/// ã€Œè¯æ³•æŠ˜å ã€çš„æ€»å…¥å£
#[inline]
pub fn lexical_fold(term: TermLexical) -> Result<Term> {
    let mut context = FoldContext::new();
    fold_term(term, &mut context)
}

/// ã€Œè¯æ³•æŠ˜å ã€çš„é€’å½’å…¥å£
/// * ğŸš©å¤§ä½“è°ƒç”¨æµç¨‹ï¼š`conversion` => `term_making` => `construct`
///   * ã€æŠ˜å ã€‘æ—¶ã€åˆ¶ä½œã€‘è¯é¡¹ï¼Œæœ€ç»ˆæ‰ã€æ„é€ ã€‘
///   * ğŸš§ã€2024-09-06 17:43:36ã€‘æœ‰å¾…å®è£…
/// * ğŸ“Œå¸¦ã€Œå˜é‡ç¼–å·åŒ–ã€é€»è¾‘
fn fold_term(term: TermLexical, context: &mut FoldContext) -> Result<Term> {
    // TODO: ç†æ¸…ã€ŒæŠ˜å æ—¶ç®€åŒ–ã€ä¸ã€Œmakeã€çš„ åŒºåˆ«/å·®å¼‚
    // ? â“ç®€åŒ–çš„æ—¶æœº
    // ? â“æ˜¯å¦è¦ã€Œè¾¹è§£æè¾¹ç®€åŒ–ã€ã€Œå†…éƒ¨å…ƒç´ è§£æç®€åŒ–åå†åˆ°æ­¤å¤„ã€
    // TODO: ç®€åŒ–å…¶ä¸­çš„ã€Œmakeã€ç›¸å…³é€‰é¡¹
    // * ğŸ“„ä½•æ—¶å¯¹ã€Œå†…éƒ¨è¯é¡¹ã€æ’åº

    /// æ›´æ–°å¹¶è¿”å›ä¸€ä¸ªã€Œå˜é‡è¯é¡¹ã€ï¼Œæ ¹æ®ä¼ å…¥çš„ã€Œå˜é‡idæ˜ å°„ã€å°†åŸã€Œå˜é‡åã€æ˜ å°„åˆ°ã€Œå˜é‡idã€
    #[inline]
    fn update_var(
        var_type: impl Into<String>,
        original_name: String,
        context: &mut FoldContext,
    ) -> Term {
        match context
            .var_id_map
            .iter()
            .position(|stored_name| &original_name == stored_name)
        {
            // * ğŸš©idä»1å¼€å§‹
            Some(existed) => Term::from_var_similar(var_type, existed + 1),
            // * ğŸš©æ–°åç§°
            None => {
                context.var_id_map.push(original_name);
                Term::from_var_similar(var_type, context.var_id_map.len())
            }
        }
    }

    macro_rules! make_error {
        () => {
            if cfg!(test) {
                anyhow::anyhow!("è¯é¡¹æ— æ•ˆ @ {}:{}", file!(), line!())
            } else {
                anyhow::anyhow!("è¯é¡¹æ— æ•ˆ")
            }
        };
    }

    // æ­£å¼å¼€å§‹
    let identifier = get_identifier(&term);
    // åœ¨æœ‰é™çš„æ ‡è¯†ç¬¦èŒƒå›´å†…åŒ¹é…
    use TermLexical::*;
    let term = match (identifier.as_str(), term) {
        // åŸå­è¯é¡¹ | âš ï¸è™½ç„¶ã€Œå•ç‹¬çš„å ä½ç¬¦ã€åœ¨OpenNARSä¸­ä¸åˆæ³•ï¼Œä½†åœ¨è§£æã€Œåƒã€æ—¶éœ€è¦ç”¨åˆ° //
        (WORD, Atom { name, .. }) => Term::make_word(name),
        (PLACEHOLDER, Atom { .. }) => Term::make_placeholder(),
        (VAR_INDEPENDENT, Atom { name, .. }) => update_var(VAR_INDEPENDENT, name, context),
        (VAR_DEPENDENT, Atom { name, .. }) => update_var(VAR_DEPENDENT, name, context),
        (VAR_QUERY, Atom { name, .. }) => update_var(VAR_QUERY, name, context),
        // å¤åˆè¯é¡¹ //
        (SET_EXT_OPERATOR, Set { terms, .. }) => {
            Term::make_set_ext_arg(fold_inner_lexical_vec(terms, context)?).ok_or(make_error!())?
        }
        (SET_INT_OPERATOR, Set { terms, .. }) => {
            Term::make_set_int_arg(fold_inner_lexical_vec(terms, context)?).ok_or(make_error!())?
        }
        (INTERSECTION_EXT_OPERATOR, Compound { terms, .. }) => {
            Term::make_intersection_ext_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(make_error!())?
        }
        (INTERSECTION_INT_OPERATOR, Compound { terms, .. }) => {
            Term::make_intersection_int_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(make_error!())?
        }
        (DIFFERENCE_EXT_OPERATOR, Compound { terms, .. }) if terms.len() == 2 => {
            let mut iter = terms.into_iter();
            let term1 = fold_inner_lexical(iter.next().unwrap(), context)?;
            let term2 = fold_inner_lexical(iter.next().unwrap(), context)?;
            Term::make_difference_ext(term1, term2).ok_or(make_error!())?
        }
        (DIFFERENCE_INT_OPERATOR, Compound { terms, .. }) if terms.len() == 2 => {
            let mut iter = terms.into_iter();
            let term1 = fold_inner_lexical(iter.next().unwrap(), context)?;
            let term2 = fold_inner_lexical(iter.next().unwrap(), context)?;
            Term::make_difference_int(term1, term2).ok_or(make_error!())?
        }
        (PRODUCT_OPERATOR, Compound { terms, .. }) => {
            Term::make_product_arg(fold_inner_lexical_vec(terms, context)?).ok_or(make_error!())?
        }
        (IMAGE_EXT_OPERATOR, Compound { terms, .. }) => {
            // ! âš ï¸ç°åœ¨è§£æå‡ºä½œä¸ºã€Œåƒä¹‹å†…å®¹ã€çš„ã€Œè¯é¡¹åºåˆ—ã€åŒ…å«ã€Œå ä½ç¬¦ã€ä½œä¸ºå†…å®¹
            let (i, terms) = fold_lexical_terms_as_image(terms, context)?;
            match i {
                // å ä½ç¬¦åœ¨é¦–ä½â‡’è§†ä½œã€Œä¹˜ç§¯ã€ | ğŸ“NAL-4ä¸­ä¿ç•™ã€Œç¬¬0ä½ã€ä½œã€Œå…³ç³»ã€è¯é¡¹
                0 => Term::make_product_arg(terms).ok_or(make_error!())?,
                _ => Term::make_image_ext_vec(terms).ok_or(make_error!())?,
            }
        }
        (IMAGE_INT_OPERATOR, Compound { terms, .. }) => {
            // ! âš ï¸ç°åœ¨è§£æå‡ºä½œä¸ºã€Œåƒä¹‹å†…å®¹ã€çš„ã€Œè¯é¡¹åºåˆ—ã€åŒ…å«ã€Œå ä½ç¬¦ã€ä½œä¸ºå†…å®¹
            let (i, terms) = fold_lexical_terms_as_image(terms, context)?;
            match i {
                // å ä½ç¬¦åœ¨é¦–ä½â‡’è§†ä½œã€Œä¹˜ç§¯ã€ | ğŸ“NAL-4ä¸­ä¿ç•™ã€Œç¬¬0ä½ã€ä½œã€Œå…³ç³»ã€è¯é¡¹
                0 => Term::make_product_arg(terms).ok_or(make_error!())?,
                _ => Term::make_image_int_vec(terms).ok_or(make_error!())?,
            }
        }
        (CONJUNCTION_OPERATOR, Compound { terms, .. }) => {
            Term::make_conjunction_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(make_error!())?
        }
        (DISJUNCTION_OPERATOR, Compound { terms, .. }) => {
            Term::make_disjunction_arg(fold_inner_lexical_vec(terms, context)?)
                .ok_or(make_error!())?
        }
        (NEGATION_OPERATOR, Compound { terms, .. }) if terms.len() == 1 => {
            // TODO: æå–å½¢å¦‚ã€Œæ•°ç»„ä¸­ã€åˆ¤æ–­æŒ‡å®šæ•°é‡å¹¶å–å‡ºæ•°ç»„ã€ã€çš„è¯­ä¹‰ `fn extract_term_vec<const N: usize>(terms: Vec<Term>) -> Result<[Term; N]>`
            // * ğŸ’¡ä½¿ç”¨ã€Œå ä½ç¬¦ã€ä½œä¸ºã€Œæ•°ç»„åˆå§‹åŒ–ã€çš„å ä½ç¬¦
            let inner = fold_inner_lexical(terms.into_iter().next().unwrap(), context)?;
            Term::make_negation(inner).ok_or(make_error!())?
        }
        (SEQUENCE_OPERATOR, Compound { terms, .. }) => {
            Term::make_sequence(fold_inner_lexical_vec(terms, context)?).ok_or(make_error!())?
        }
        // é™ˆè¿°
        (
            INHERITANCE_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_inheritance(
            fold_inner_lexical(*subject, context)?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(make_error!())?,
        (
            SIMILARITY_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_similarity(
            fold_inner_lexical(*subject, context)?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(make_error!())?,
        (
            IMPLICATION_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_implication(
            fold_inner_lexical(*subject, context)?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(make_error!())?,
        (
            TEMPORAL_IMPLICATION_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_temporal_implication(
            fold_inner_lexical(*subject, context)?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(make_error!())?,
        (
            EQUIVALENCE_RELATION,
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_equivalence(
            fold_inner_lexical(*subject, context)?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(make_error!())?,
        (
            INSTANCE_RELATION, // æ´¾ç”Ÿç³»è¯/å®ä¾‹
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_inheritance(
            Term::make_set_ext_arg(vec![fold_inner_lexical(*subject, context)?])
                .ok_or(make_error!())?,
            fold_inner_lexical(*predicate, context)?,
        )
        .ok_or(make_error!())?,
        (
            PROPERTY_RELATION, // æ´¾ç”Ÿç³»è¯/å±æ€§
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_inheritance(
            fold_inner_lexical(*subject, context)?,
            Term::make_set_int_arg(vec![fold_inner_lexical(*predicate, context)?])
                .ok_or(make_error!())?,
        )
        .ok_or(make_error!())?,
        (
            INSTANCE_PROPERTY_RELATION, // æ´¾ç”Ÿç³»è¯/å®ä¾‹å±æ€§
            Statement {
                subject, predicate, ..
            },
        ) => Term::make_inheritance(
            Term::make_set_ext_arg(vec![fold_inner_lexical(*subject, context)?])
                .ok_or(make_error!())?,
            Term::make_set_int_arg(vec![fold_inner_lexical(*predicate, context)?])
                .ok_or(make_error!())?,
        )
        .ok_or(make_error!())?,
        // å…¶å®ƒæƒ…å†µâ‡’ä¸åˆæ³•
        (identifier, this) => return Err(anyhow!("æ ‡è¯†ç¬¦ä¸ºã€Œ{identifier}ã€çš„éæ³•è¯é¡¹ï¼š{this:?}")),
    };
    Ok(term)
}

/// è¯æ³•æŠ˜å /å•ä¸ªè½¬æ¢
/// * âš ï¸æ‹’ç»å‘ˆé€’å ä½ç¬¦ï¼šä¸å…è®¸ã€Œåƒå ä½ç¬¦ã€åœ¨é™¤äº†ã€Œå¤–å»¶åƒ/å†…æ¶µåƒã€å¤–çš„è¯é¡¹ä¸­å‡ºç°
#[inline]
fn fold_inner_lexical(term: TermLexical, context: &mut FoldContext) -> Result<Term> {
    // * ğŸš©æ­£å¸¸è½¬æ¢
    let term = fold_term(term, context)?;
    // * ğŸš©æ‹¦æˆªè§£æå‡ºçš„ã€Œå ä½ç¬¦ã€è¯é¡¹
    if term.is_placeholder() {
        return Err(anyhow!("è¯æ³•æŠ˜å é”™è¯¯ï¼šå ä½ç¬¦ä»…èƒ½ç›´å±äº å¤–å»¶åƒ/å†…æ¶µåƒ è¯é¡¹"));
    }
    // * ğŸš©æ­£å¸¸è¿”å›
    Ok(term)
}

/// è¯æ³•æŠ˜å  / ä»ã€Œæ•°ç»„ã€ä¸­è½¬æ¢
/// * ğŸ¯å°†ã€Œè¯æ³•Narseseè¯é¡¹æ•°ç»„ã€è½¬æ¢ä¸ºã€Œå†…éƒ¨è¯é¡¹æ•°ç»„ã€
///   * ğŸ“„ç”¨äºå¤åˆè¯é¡¹å†…éƒ¨å…ƒç´ çš„è§£æ
///   * â„¹ï¸å¯¹äºã€Œå¤–å»¶åƒ/å†…æ¶µåƒã€é‡‡ç”¨ç‰¹æ®Šæ–¹æ³•
/// * ğŸ“Œåœ¨ã€Œæ— æ³•åŒæ—¶`map`ä¸`?`ã€æ—¶ç‹¬ç«‹æˆå‡½æ•°
/// * âš ï¸ä¸å…è®¸æ„é€ ç©ºè¯é¡¹æ•°ç»„ï¼šå‚è€ƒNALï¼Œä¸å…è®¸ç©ºé›†
/// * âŒã€2024-07-08 23:20:02ã€‘ç°ä¸å…è®¸åœ¨å…¶ä¸­è§£æå‡ºã€Œå ä½ç¬¦ã€è¯é¡¹
///   * ğŸ¯ææ—©é¿å…ã€Œåƒå ä½ç¬¦æº¢å‡ºã€æƒ…å½¢
#[inline]
fn fold_inner_lexical_vec(terms: Vec<TermLexical>, context: &mut FoldContext) -> Result<Vec<Term>> {
    let mut v = vec![];
    for term in terms {
        v.push(fold_inner_lexical(term, context)?);
    }
    check_folded_terms(v)
}

/// æ£€æŸ¥æŠ˜å å¥½äº†çš„è¯é¡¹è¡¨
/// * ğŸš©ã€2024-06-14 00:13:29ã€‘ç›®å‰ä»…æ£€æŸ¥ã€Œæ˜¯å¦ä¸ºç©ºé›†ã€
#[inline]
fn check_folded_terms(v: Vec<Term>) -> Result<Vec<Term>> {
    match v.is_empty() {
        true => Err(anyhow!("è¯æ³•æŠ˜å é”™è¯¯ï¼šNALä¸å…è®¸æ„é€ ç©ºé›†")),
        false => Ok(v),
    }
}

/// è¯æ³•æŠ˜å  / ä»ã€Œæ•°ç»„ã€ä¸­è½¬æ¢æˆã€Œåƒã€
/// * ğŸ¯å°†ã€Œè¯æ³•Narseseè¯é¡¹æ•°ç»„ã€è½¬æ¢ä¸ºã€Œåƒã€æ‰€éœ€çš„ã€Œå¸¦ç´¢å¼•è¯é¡¹æ•°ç»„ã€
#[inline]
fn fold_lexical_terms_as_image(
    terms: Vec<TermLexical>,
    context: &mut FoldContext,
) -> Result<(usize, Vec<Term>)> {
    // æ„é€ ã€Œç»„åˆ†ã€
    let mut v = vec![];
    let mut placeholder_index = 0;
    for (i, term) in terms.into_iter().enumerate() {
        let term: Term = fold_term(term, context)?;
        // è¯†åˆ«ã€Œå ä½ç¬¦ä½ç½®ã€
        // ğŸ†•ã€2024-04-21 01:12:50ã€‘ä¸åŒäºOpenNARSï¼šåªä¼šç•™ä¸‹ï¼ˆä¸”ä½ç½®å–å†³äºï¼‰æœ€åä¸€ä¸ªå ä½ç¬¦
        // ğŸ“„OpenNARSåœ¨ã€Œæ²¡æ‰¾åˆ°å ä½ç¬¦ã€æ—¶ï¼Œä¼šå°†ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºå ä½ç¬¦ï¼Œç„¶åæŠŠã€Œå ä½ç¬¦ç´¢å¼•ã€å›ºå®šä¸º`1`
        match term.is_placeholder() {
            true => {
                placeholder_index = i;
                if i > 0 {
                    // * ğŸš©å ä½ç¬¦ä¸èƒ½æ˜¯ç¬¬ä¸€ä¸ªâ‡’å¦åˆ™ä½œä¸ºã€Œä¹˜ç§¯ã€æäº¤ï¼ˆä¸åŒ…å«å ä½ç¬¦ï¼‰
                    v.push(term);
                }
            }
            // * ğŸš©ç°åœ¨é™¤äº†ã€Œå ä½ç¬¦åœ¨ç¬¬ä¸€ä¸ªã€ï¼ˆä¹˜ç§¯ï¼‰çš„æƒ…å½¢ï¼Œå…¶å®ƒå‡å°†ã€Œå ä½ç¬¦ã€ç®—å…¥åœ¨ã€Œå…ƒç´ ã€ä¸­
            false => v.push(term),
        }
    }
    Ok((placeholder_index, check_folded_terms(v)?))
}

/// å•å…ƒæµ‹è¯•
#[cfg(test)]
mod tests {
    use super::*;
    use crate::{ok, util::AResult};
    use nar_dev_utils::macro_once;
    use narsese::{
        conversion::{
            inter_type::lexical_fold::TryFoldInto,
            string::impl_lexical::format_instances::FORMAT_ASCII,
        },
        lexical::Term as LexicalTerm,
        lexical_nse_term as l_term,
    };

    /// æµ‹è¯• / è¯æ³•æŠ˜å 
    #[test]
    fn test_lexical_fold() -> AResult {
        fn test(t: LexicalTerm) -> Result<Term> {
            print!("{:?} => ", FORMAT_ASCII.format(&t));
            // ä¸‰ç§è§£æè·¯å¾„
            let term_1 = Term::try_from(t.clone())?;
            let term_2 = t.clone().try_fold_into(&())?;
            let term_3 = Term::from_lexical(t)?;
            // åˆ¤æ–­è·¯å¾„ç­‰ä»·æ€§
            assert_eq!(term_1, term_2);
            assert_eq!(term_1, term_3);
            assert_eq!(term_2, term_3);
            // æ‰“å°
            let term = term_1;
            println!("{:?}", term.format_name());
            Ok(term)
        }
        macro_once! {
            // * ğŸš©æ¨¡å¼ï¼šè¯é¡¹å­—ç¬¦ä¸²
            macro test($($term:literal)*) {
                $(
                    test(l_term!($term))?;
                )*
            }
            "<A --> B>"
            "(&&, C, B, A, (/, A, _, B))"
            // "<(*, {SELF}, x, y) --> ^left>" // ! âš ï¸ã€2024-04-25 10:02:20ã€‘ç°åœ¨å¯¹ã€Œæ“ä½œç¬¦ã€ä¸å†æ”¯æŒ
            "[2, 1, 0, $0, #1, ?2]"
            "<A <-> {B}>" // ! åŸå…ˆçš„ã€Œç±»é‡è¨€å¼ã€`<A <-> {A}>`æ˜¯æ— æ•ˆçš„
            "<{A} <=> B>" // ! åŸå…ˆçš„ã€Œç±»é‡è¨€å¼ã€`<{B} <=> B>`æ˜¯æ— æ•ˆçš„
            "<{SELF} ==> (--, [good])>"
        }
        ok!()
    }

    /// æµ‹è¯• / è¯æ³•æŠ˜å /å¤±è´¥æƒ…å†µ
    /// * âš ï¸ä»…è€ƒè™‘è¯æ³•æŠ˜å å¤±è´¥ï¼Œä¸è€ƒè™‘è§£æå¤±è´¥
    #[test]
    fn test_lexical_fold_err() -> AResult {
        fn test(t: LexicalTerm) -> AResult {
            let t_s = FORMAT_ASCII.format(&t);
            let e = Term::try_from(t.clone()).expect_err(&format!("éæ³•è¯é¡¹{t_s:?}å¼‚å¸¸é€šè¿‡è§£æ"));
            println!("{t_s:?} => {e}");
            ok!()
        }
        macro_once! {
            // * ğŸš©æ¨¡å¼ï¼šè¯é¡¹å­—ç¬¦ä¸²
            macro test($($term:literal)*) {
                $(
                    test(l_term!($term))?;
                )*
            }
            // * ğŸ“„éæ³•æ ‡è¯†ç¬¦
            // * ğŸš©ã€2024-04-25 10:02:20ã€‘ç°åœ¨å¯¹ã€Œæ“ä½œç¬¦ã€ä¸å†æ”¯æŒ
            "^operator" // ^operator
            "<(*, {SELF}, x, y) --> ^left>" // ^left
            "<X =/> Y>" // =/>
            "<X =|> Y>" // =|>
            "<X </> Y>" // </>
            "+123" // +123
            "(&/, 1, 2, 3)" // &/
            "(&|, 3, 2, 1)" // &|
            // * ğŸ“„è¯é¡¹æ•°ç›®ä¸å¯¹
            "(-, A, B, C)"
            "(-, A)"
            "(--, A, B)"
            // * ğŸ“„ç©ºé›†
            // * ğŸ“„æº¢å‡ºçš„å ä½ç¬¦
            "{_}"
            "{A, B, _}"
            "[_]"
            "[A, B, _]"
            "<A --> _>"
            "<A <-> _>"
            "<A ==> _>"
            "<A <=> _>"
            "<_ --> _>"
            "<_ <-> _>"
            "<_ ==> _>"
            "<_ <=> _>"
            "(&, _, A, B)"
            "(-, _, B)"
            "(-, A, _)"
            "(--, _)"
            "(&&, (*, [A, B, _]), A, B)"
        }
        ok!()
    }

    /// æµ‹è¯• / å˜é‡é‡ç¼–å·
    /// * ğŸ“„nse  `<(&&,<(*,{$1},{$2},$d)-->æ–¹å‘>,<(*,{$1},$c)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$2},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>)==><(*,$d,$c,{$1},{$2})-->[åŒè‰²è¿ç©º]>>.%1.00;0.99%`
    ///   * ğŸ•’ã€2024-07-02 00:32:46ã€‘
    ///   * é¢„æœŸï¼š`<(&&,<(*,{$1},{$2},$3)-->æ–¹å‘>,<(*,{$1},$4)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$2},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>)==><(*,$3,$4,{$1},{$2})-->[åŒè‰²è¿ç©º]>>. %1.0;0.99%`
    ///   * å½“å‰ï¼š`<(&&,<(*,{$1},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$1},$2)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$1},{$2},$3)-->æ–¹å‘>)==><(*,$1,$2,{$3},{$4})-->[åŒè‰²è¿ç©º]>>.%1.0000;0.9900%`
    ///   * é¢„æœŸã®æ˜ å°„ï¼š
    ///     * `$1` => `$1`
    ///     * `$2` => `$2`
    ///     * `$d` => `$3`
    ///     * `$c` => `$4`
    ///   * å½“å‰ã®æ˜ å°„ï¼š
    ///     * `$1` => `$1`
    ///     * `$2` => `$2`ã€`$1`@ã€Œæ— ç¼ºé™·ã€
    ///     * `$d` => `$3`ã€`$1`@åŒè‰²è¿ç©º
    ///     * `$c` => `$2`
    /// * âœ…ã€2024-07-02 01:06:12ã€‘ç°åœ¨æˆåŠŸï¼šè‡³å°‘æ˜¯å”¯ä¸€æ˜ å°„äº†
    ///     * `$1` => `$1`
    ///     * `$2` => `$2`
    ///     * `$d` => `$4`
    ///     * `$c` => `$3`
    #[test]
    fn test_var_map() -> AResult {
        // è¯æ³•Narseseå±•ç¤º
        let lexical = l_term!(<(&&,<(*,{$1},{$2},$d)-->æ–¹å‘>,<(*,{$1},$c)-->æ ¼ç‚¹çŠ¶æ€>,<(*,{$2},æ— ç¼ºé™·)-->æ ¼ç‚¹çŠ¶æ€>)==><(*,$d,$c,{$1},{$2})-->[åŒè‰²è¿ç©º]>>);
        println!("{}", FORMAT_ASCII.format(&lexical));

        // è¯æ³•æŠ˜å 
        let term1 = Term::from_lexical(lexical.clone())?;
        let term1_s = term1.format_ascii();
        println!("{term1_s}");

        // å†…éƒ¨æŠ˜å æ–¹æ³•
        let mut context = FoldContext::new();
        let term2 = fold_term(lexical.clone(), &mut context)?;
        let term2_s = term2.format_ascii();
        println!("{term2_s}");
        assert_eq!(term1_s, term2_s); // ä¸¤ç§è½¬æ¢ä¹‹åï¼Œå­—ç¬¦ä¸²å½¢å¼åº”è¯¥ç›¸ç­‰

        // å¯¹æ¯”ï¼šæ˜ å°„è¡¨
        println!("{:?}", context);
        for (var_i, original_name) in context.var_id_map.iter().enumerate() {
            println!("{original_name} => {}", var_i + 1);
        }
        let expected = [("1", 1), ("2", 2), ("d", 3), ("c", 4)];
        for (original_name, var_i) in expected.iter() {
            // æ–­è¨€æ˜ å°„è¡¨ç›¸ç­‰
            assert_eq!(context.var_id_map[*var_i - 1], *original_name);
        }
        ok!()
    }
}
