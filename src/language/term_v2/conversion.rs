//! ä¸å…¶å®ƒç±»å‹ç›¸äº’è½¬æ¢
//! * ğŸ¯è½¬æ¢ä¸ºã€Œè¯æ³•Narseseã€ä»¥ä¾¿ã€Œè·å–åç§°ã€

use super::*;
use anyhow::{anyhow, Result};
use narsese::{
    conversion::{
        inter_type::lexical_fold::TryFoldInto, string::impl_lexical::format_instances::FORMAT_ASCII,
    },
    lexical::Term as TermLexical,
};
use std::str::FromStr;

// æ ¼å¼åŒ–æ‰€ç”¨å¸¸é‡
const COMPONENT_OPENER: &str = "(";
const COMPONENT_CLOSER: &str = ")";
const COMPONENT_SEPARATOR: &str = " ";

/// è¯é¡¹â‡’å­—ç¬¦ä¸²
/// * ğŸ¯ç”¨äºæ›´å¥½åœ°æ‰“å°ã€Œè¯é¡¹ã€åç§°
impl Term {
    pub fn format_name(&self) -> String {
        let id = &self.identifier;
        match &*self.components {
            // ç©ºç»„åˆ†
            TermComponents::Empty => id.clone(),
            // åç§° | åŸå­è¯é¡¹
            TermComponents::Named(name) => id.clone() + name,
            // ä¸€å…ƒ
            TermComponents::Unary(term) => {
                // ğŸ“„ "(-- A)"
                manipulate!(
                    String::new()
                    => {+= COMPONENT_OPENER}#
                    => {+= id}#
                    => {+= COMPONENT_SEPARATOR}#
                    => {+= &term.format_name()}#
                    => {+= COMPONENT_CLOSER}#
                )
            }
            // äºŒå…ƒ
            TermComponents::Binary(term1, term2) => {
                // ğŸ“„ "(A --> B)"
                manipulate!(
                    String::new()
                    => {+= COMPONENT_OPENER}#
                    => {+= &term1.format_name()}#
                    => {+= COMPONENT_SEPARATOR}#
                    => {+= id}#
                    => {+= COMPONENT_SEPARATOR}#
                    => {+= &term2.format_name()}#
                    => {+= COMPONENT_CLOSER}#
                )
            }
            // å¤šå…ƒ
            TermComponents::Multi(terms) => {
                let mut s = id.to_string() + COMPONENT_OPENER;
                let mut terms = terms.iter();
                if let Some(t) = terms.next() {
                    s += &t.format_name();
                }
                for t in terms {
                    s += COMPONENT_SEPARATOR;
                    s += &t.format_name();
                }
                s + COMPONENT_CLOSER
            }
            // å¤šå…ƒ+ç´¢å¼•
            TermComponents::MultiIndexed(index, terms) => {
                let mut s = id.to_string() + COMPONENT_OPENER;
                let mut terms = terms.iter();
                // åˆ†ã€Œå ä½ç¬¦åœ¨å¼€å¤´ã€ä¸ã€Œå ä½ç¬¦åœ¨åå¤´ã€
                if *index == 0 {
                    s += PLACEHOLDER;
                    for term in terms {
                        s += COMPONENT_SEPARATOR;
                        s += &term.format_name();
                    }
                } else {
                    // * âš ï¸ã€2024-04-22 13:02:41ã€‘SAFETY: ç»ç”±ã€Œåƒã€çš„æ„é€ å‡½æ•°ä¿è¯ï¼Œå ä½ç¬¦å¿…å®šåœ¨ç•Œå†…
                    // å ä½ç¬¦å‰çš„è¯é¡¹
                    s += &terms.next().unwrap().format_name();
                    for _ in 1..*index {
                        s += COMPONENT_SEPARATOR;
                        s += &terms.next().unwrap().format_name();
                    }
                    // å ä½ç¬¦
                    s += COMPONENT_SEPARATOR;
                    s += PLACEHOLDER;
                    // å ä½ç¬¦åçš„è¯é¡¹
                    for term in terms {
                        s += COMPONENT_SEPARATOR;
                        s += &term.format_name();
                    }
                }
                s + COMPONENT_CLOSER
            }
        }
    }
}

/// è¯é¡¹â‡’è¯æ³•Narsese
impl From<&Term> for TermLexical {
    fn from(value: &Term) -> Self {
        use TermComponents::*;
        let (id, comp) = value.id_comp();
        match (id, comp) {
            // ä¸“ç”¨ / é›†åˆè¯é¡¹ | é»˜è®¤å·²æ’åº
            (SET_EXT_OPERATOR | SET_INT_OPERATOR, Multi(v)) => {
                let v = v.iter().map(TermLexical::from).collect::<Vec<_>>();
                Self::new_compound(id, v)
            }
            // ä¸“ç”¨ / é™ˆè¿°
            (
                INHERITANCE_RELATION | SIMILARITY_RELATION | IMPLICATION_RELATION
                | EQUIVALENCE_RELATION,
                Binary(subj, pred),
            ) => Self::new_statement(id, subj.into(), pred.into()),
            // é€šç”¨ / ç©ºï¼šä»…å‰ç¼€
            (_, Empty) => Self::new_atom(id, ""),
            // é€šç”¨ / å…·åï¼šå‰ç¼€+è¯é¡¹å
            (_, Named(name)) => Self::new_atom(id, name),
            // é€šç”¨ / ä¸€å…ƒ
            (_, Unary(term)) => Self::new_compound(id, vec![term.into()]),
            // é€šç”¨ / äºŒå…ƒ
            (_, Binary(subj, pred)) => Self::new_compound(id, vec![subj.into(), pred.into()]),
            // å¤šå…ƒ
            (_, Multi(terms)) => {
                Self::new_compound(id, terms.iter().map(TermLexical::from).collect())
            }
            // é€šç”¨ / å¸¦ç´¢å¼•
            (_, MultiIndexed(i, v)) => {
                // é€ä¸ªè½¬æ¢ç»„åˆ†
                let mut v = v.iter().map(TermLexical::from).collect::<Vec<_>>();
                // åˆ›å»ºå¹¶æ’å…¥ã€Œå ä½ç¬¦ã€
                let placeholder = Term::new_placeholder();
                let placeholder = (&placeholder).into();
                v.insert(*i, placeholder);
                // æ„é€  & è¿”å›
                Self::new_compound(id, v)
            }
        }
    }
}

/// è¯æ³•æŠ˜å  / è·å–ã€Œæ ‡è¯†ç¬¦ã€
/// * ğŸ¯ä»ã€Œè¯æ³•Narseseã€è·å–ã€Œæ ‡è¯†ç¬¦ã€ï¼Œä»¥ä¾¿åç»­æ ¹æ®ã€Œæ ‡è¯†ç¬¦ã€åˆ†å‘é€»è¾‘
/// * ğŸš©å¯¹ã€Œé›†åˆã€è¯é¡¹ï¼šå°†å·¦å³æ‹¬å¼§ç›´æ¥æ‹¼æ¥ï¼Œä½œä¸ºæ–°çš„ã€ç»Ÿä¸€çš„ã€Œæ ‡è¯†ç¬¦ã€
fn get_identifier(term: &TermLexical) -> String {
    match term {
        TermLexical::Atom { prefix, .. } => prefix.clone(),
        TermLexical::Compound { connecter, .. } => connecter.clone(),
        TermLexical::Set {
            left_bracket,
            right_bracket,
            ..
        } => left_bracket.to_string() + right_bracket,
        TermLexical::Statement { copula, .. } => copula.clone(),
    }
}

/// è¯æ³•æŠ˜å  / ä»ã€Œæ•°ç»„ã€ä¸­è½¬æ¢
/// * ğŸ¯å°†ã€Œè¯æ³•Narseseè¯é¡¹æ•°ç»„ã€è½¬æ¢ä¸ºã€Œå†…éƒ¨è¯é¡¹æ•°ç»„ã€
/// * ğŸ“Œåœ¨ã€Œæ— æ³•åŒæ—¶`map`ä¸`?`ã€æ—¶ç‹¬ç«‹æˆå‡½æ•°
/// * âš ï¸ä¸å…è®¸æ„é€ ç©ºè¯é¡¹æ•°ç»„ï¼šå‚è€ƒNALï¼Œä¸å…è®¸ç©ºé›†
#[inline]
fn fold_lexical_terms(terms: Vec<TermLexical>) -> Result<Vec<Term>> {
    let mut v = vec![];
    for term in terms {
        v.push(term.try_into()?);
    }
    check_folded_terms(v)
}

fn check_folded_terms(v: Vec<Term>) -> Result<Vec<Term>> {
    match v.is_empty() {
        true => Err(anyhow!("NALä¸å…è®¸æ„é€ ç©ºé›†")),
        false => Ok(v),
    }
}

/// è¯æ³•æŠ˜å  / ä»ã€Œæ•°ç»„ã€ä¸­è½¬æ¢æˆã€Œåƒã€
/// * ğŸ¯å°†ã€Œè¯æ³•Narseseè¯é¡¹æ•°ç»„ã€è½¬æ¢ä¸ºã€Œåƒã€æ‰€éœ€çš„ã€Œå¸¦ç´¢å¼•è¯é¡¹æ•°ç»„ã€
#[inline]
fn fold_lexical_terms_as_image(terms: Vec<TermLexical>) -> Result<(usize, Vec<Term>)> {
    // æ„é€ ã€Œç»„åˆ†ã€
    let mut v = vec![];
    let mut placeholder_index = 0;
    for (i, term) in terms.into_iter().enumerate() {
        let term: Term = term.try_into()?;
        // è¯†åˆ«ã€Œå ä½ç¬¦ä½ç½®ã€
        // ğŸ†•ã€2024-04-21 01:12:50ã€‘ä¸åŒäºOpenNARSï¼šåªä¼šç•™ä¸‹ï¼ˆä¸”ä½ç½®å–å†³äºï¼‰æœ€åä¸€ä¸ªå ä½ç¬¦
        // ğŸ“„OpenNARSåœ¨ã€Œæ²¡æ‰¾åˆ°å ä½ç¬¦ã€æ—¶ï¼Œä¼šå°†ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºå ä½ç¬¦ï¼Œç„¶åæŠŠã€Œå ä½ç¬¦ç´¢å¼•ã€å›ºå®šä¸º`1`
        match term.is_placeholder() {
            true => placeholder_index = i,
            false => v.push(term),
        }
    }
    Ok((placeholder_index, check_folded_terms(v)?))
}

/// è¯æ³•æŠ˜å 
impl TryFoldInto<'_, Term, anyhow::Error> for TermLexical {
    type Folder = ();

    /// ğŸ’­ã€2024-04-21 14:44:15ã€‘ç›®å‰æ­¤ä¸­æ–¹æ³•ã€Œç›¸è¾ƒä¿å®ˆã€
    /// * ğŸ“Œä¸è¯æ³•Narseseä¸¥æ ¼å¯¹åº”ï¼ˆASCIIï¼‰
    /// * âœ…åŸºæœ¬ä¿è¯ã€Œè§£æç»“æœå‡ä¿è¯ã€åˆæ³•ã€ã€
    fn try_fold_into(self, _: &'_ Self::Folder) -> Result<Term> {
        let identifier = get_identifier(&self);
        let self_str = FORMAT_ASCII.format(&self);
        // åœ¨æœ‰é™çš„æ ‡è¯†ç¬¦èŒƒå›´å†…åŒ¹é…
        use TermLexical::*;
        let term = match (identifier.as_str(), self) {
            // åŸå­è¯é¡¹ | âš ï¸è™½ç„¶ã€Œå•ç‹¬çš„å ä½ç¬¦ã€åœ¨OpenNARSä¸­ä¸åˆæ³•ï¼Œä½†åœ¨è§£æã€Œåƒã€æ—¶éœ€è¦ç”¨åˆ° //
            (WORD, Atom { name, .. }) => Term::new_word(name),
            (PLACEHOLDER, Atom { .. }) => Term::new_placeholder(),
            (VAR_INDEPENDENT, Atom { name, .. }) => Term::new_var_i(name),
            (VAR_DEPENDENT, Atom { name, .. }) => Term::new_var_d(name),
            (VAR_QUERY, Atom { name, .. }) => Term::new_var_q(name),
            // å¤åˆè¯é¡¹ //
            (SET_EXT_OPERATOR, Set { terms, .. }) => Term::new_set_ext(fold_lexical_terms(terms)?),
            (SET_INT_OPERATOR, Set { terms, .. }) => Term::new_set_int(fold_lexical_terms(terms)?),
            (INTERSECTION_EXT_OPERATOR, Compound { terms, .. }) => {
                Term::new_intersect_ext(fold_lexical_terms(terms)?)
            }
            (INTERSECTION_INT_OPERATOR, Compound { terms, .. }) => {
                Term::new_intersect_int(fold_lexical_terms(terms)?)
            }
            (DIFFERENCE_EXT_OPERATOR, Compound { terms, .. }) if terms.len() == 2 => {
                let mut iter = terms.into_iter();
                let term1 = iter.next().unwrap().try_into()?;
                let term2 = iter.next().unwrap().try_into()?;
                Term::new_diff_ext(term1, term2)
            }
            (DIFFERENCE_INT_OPERATOR, Compound { terms, .. }) if terms.len() == 2 => {
                let mut iter = terms.into_iter();
                let term1 = iter.next().unwrap().try_into()?;
                let term2 = iter.next().unwrap().try_into()?;
                Term::new_diff_int(term1, term2)
            }
            (PRODUCT_OPERATOR, Compound { terms, .. }) => {
                Term::new_product(fold_lexical_terms(terms)?)
            }
            (IMAGE_EXT_OPERATOR, Compound { terms, .. }) => {
                let (i, terms) = fold_lexical_terms_as_image(terms)?;
                match i {
                    // å ä½ç¬¦åœ¨é¦–ä½â‡’è§†ä½œã€Œä¹˜ç§¯ã€ | ğŸ“NAL-4ä¸­ä¿ç•™ã€Œç¬¬0ä½ã€ä½œã€Œå…³ç³»ã€è¯é¡¹
                    0 => Term::new_product(terms),
                    _ => Term::new_image_ext(i, terms)?,
                }
            }
            (IMAGE_INT_OPERATOR, Compound { terms, .. }) => {
                let (i, terms) = fold_lexical_terms_as_image(terms)?;
                match i {
                    // å ä½ç¬¦åœ¨é¦–ä½â‡’è§†ä½œã€Œä¹˜ç§¯ã€ | ğŸ“NAL-4ä¸­ä¿ç•™ã€Œç¬¬0ä½ã€ä½œã€Œå…³ç³»ã€è¯é¡¹
                    0 => Term::new_product(terms),
                    _ => Term::new_image_int(i, terms)?,
                }
            }
            (CONJUNCTION_OPERATOR, Compound { terms, .. }) => {
                Term::new_conjunction(fold_lexical_terms(terms)?)
            }
            (DISJUNCTION_OPERATOR, Compound { terms, .. }) => {
                Term::new_disjunction(fold_lexical_terms(terms)?)
            }
            (NEGATION_OPERATOR, Compound { terms, .. }) if terms.len() == 1 => {
                Term::new_negation(terms.into_iter().next().unwrap().try_into()?)
            }
            // é™ˆè¿°
            (
                INHERITANCE_RELATION,
                Statement {
                    subject, predicate, ..
                },
            ) => Term::new_inheritance(subject.try_fold_into(&())?, predicate.try_fold_into(&())?),
            (
                SIMILARITY_RELATION,
                Statement {
                    subject, predicate, ..
                },
            ) => Term::new_similarity(subject.try_fold_into(&())?, predicate.try_fold_into(&())?),
            (
                IMPLICATION_RELATION,
                Statement {
                    subject, predicate, ..
                },
            ) => Term::new_implication(subject.try_fold_into(&())?, predicate.try_fold_into(&())?),
            (
                EQUIVALENCE_RELATION,
                Statement {
                    subject, predicate, ..
                },
            ) => Term::new_equivalence(subject.try_fold_into(&())?, predicate.try_fold_into(&())?),
            (
                INSTANCE_RELATION, // æ´¾ç”Ÿç³»è¯/å®ä¾‹
                Statement {
                    subject, predicate, ..
                },
            ) => Term::new_inheritance(
                Term::new_set_ext(vec![subject.try_fold_into(&())?]),
                predicate.try_fold_into(&())?,
            ),

            (
                PROPERTY_RELATION, // æ´¾ç”Ÿç³»è¯/å±æ€§
                Statement {
                    subject, predicate, ..
                },
            ) => Term::new_inheritance(
                subject.try_fold_into(&())?,
                Term::new_set_int(vec![predicate.try_fold_into(&())?]),
            ),
            (
                INSTANCE_PROPERTY_RELATION, // æ´¾ç”Ÿç³»è¯/å®ä¾‹å±æ€§
                Statement {
                    subject, predicate, ..
                },
            ) => Term::new_inheritance(
                Term::new_set_ext(vec![subject.try_fold_into(&())?]),
                Term::new_set_int(vec![predicate.try_fold_into(&())?]),
            ),
            // å…¶å®ƒæƒ…å†µâ‡’ä¸åˆæ³•
            _ => return Err(anyhow!("éæ³•è¯é¡¹ï¼š{self_str:?}")),
        };
        Ok(term)
    }
    /*
    /// ğŸ’­ã€2024-04-21 13:40:40ã€‘ç›®å‰è¿™ç§æ–¹æ³•è¿˜æ˜¯ã€Œè¿‡äºç²—æ”¾ã€
    ///   * âš ï¸å®¹è®¸ç³»ç»Ÿå†…æ²¡æœ‰çš„è¯é¡¹ç±»å‹
    ///   * âš ï¸å®¹è®¸ã€å³ä¾¿æ ‡è¯†ç¬¦åœ¨å®šä¹‰å†…ï¼Œä½†ã€ç»„åˆ†ã€ç±»å‹ä¸åŒã€‘çš„æƒ…å†µ
    fn try_fold_into(self, _: &'_ Self::Folder) -> Result<Term> {
        let identifier = get_identifier(&self);
        use TermLexical::*;
        let term = match (identifier.as_str(), self) {
            // ä¸“ç”¨ / å ä½ç¬¦
            (PLACEHOLDER, _) => Term::new_placeholder(),
            // ä¸“ç”¨ / ä¸€å…ƒå¤åˆè¯é¡¹
            (NEGATION_OPERATOR, Compound { mut terms, .. }) => {
                // ä»…åœ¨é•¿åº¦ä¸º1æ—¶è¿”å›æˆåŠŸ
                if terms.len() == 1 {
                    // ! âš ï¸è‹¥ä½¿ç”¨`get`ä¼šå¯¼è‡´ã€Œé‡å¤å¼•ç”¨ã€
                    let term = unsafe { terms.pop().unwrap_unchecked().try_fold_into(&())? };
                    Term::new_negation(term)
                } else {
                    return Err(anyhow!("éæ³•çš„ä¸€å…ƒå¤åˆè¯é¡¹ç»„åˆ†ï¼š{terms:?}"));
                }
            }
            // ä¸“ç”¨ / äºŒå…ƒå¤åˆè¯é¡¹ï¼ˆæœ‰åºï¼‰
            (DIFFERENCE_EXT_OPERATOR | DIFFERENCE_INT_OPERATOR, Compound { mut terms, .. }) => {
                // ä»…åœ¨é•¿åº¦ä¸º2æ—¶è¿”å›æˆåŠŸ
                if terms.len() == 2 {
                    // ! âš ï¸è‹¥ä½¿ç”¨`get`ä¼šå¯¼è‡´ã€Œé‡å¤å¼•ç”¨ã€
                    let term2 = unsafe { terms.pop().unwrap_unchecked().try_fold_into(&())? };
                    let term1 = unsafe { terms.pop().unwrap_unchecked().try_fold_into(&())? };
                    Term::new(identifier, TermComponents::Binary(term1, term2))
                } else {
                    return Err(anyhow!("éæ³•çš„äºŒå…ƒå¤åˆè¯é¡¹ç»„åˆ†ï¼š{terms:?}"));
                }
            }
            // ä¸“ç”¨ / æ— åºé™ˆè¿°
            (
                SIMILARITY_RELATION | EQUIVALENCE_RELATION,
                Statement {
                    subject, predicate, ..
                },
            ) => Term::new(
                identifier,
                TermComponents::new_binary_unordered(
                    subject.try_fold_into(&())?,
                    predicate.try_fold_into(&())?,
                ),
            ),
            // ä¸“ç”¨ / æ— åºå¤åˆè¯é¡¹ | ä¸å«ã€Œè¯é¡¹é›†ã€ï¼ˆåœ¨ã€Œé›†åˆè¯é¡¹ã€ä¸­ï¼‰
            (
                INTERSECTION_EXT_OPERATOR
                | INTERSECTION_INT_OPERATOR
                | CONJUNCTION_OPERATOR
                | DISJUNCTION_OPERATOR,
                Compound { terms, .. },
            ) => Term::new(
                identifier,
                // è§†ä½œã€Œå¤šå…ƒé›†åˆã€ï¼šæ’åº & å»é‡
                TermComponents::new_multi_set(vec_from_lexical_terms(terms)?),
            ),
            // ä¸“ç”¨ / åƒ
            (IMAGE_EXT_OPERATOR | IMAGE_INT_OPERATOR, Compound { terms, .. }) => {
                // æ„é€ ã€Œç»„åˆ†ã€
                let mut v = vec![];
                let mut placeholder_index = 0;
                for (i, term) in terms.into_iter().enumerate() {
                    let term: Term = term.try_fold_into(&())?;
                    // è¯†åˆ«ã€Œå ä½ç¬¦ä½ç½®ã€
                    // ğŸ†•ã€2024-04-21 01:12:50ã€‘ä¸åŒäºOpenNARSï¼šåªä¼šç•™ä¸‹ï¼ˆä¸”ä½ç½®å–å†³äºï¼‰æœ€åä¸€ä¸ªå ä½ç¬¦
                    // ğŸ“„OpenNARSåœ¨ã€Œæ²¡æ‰¾åˆ°å ä½ç¬¦ã€æ—¶ï¼Œä¼šå°†ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºå ä½ç¬¦ï¼Œç„¶åæŠŠã€Œå ä½ç¬¦ç´¢å¼•ã€å›ºå®šä¸º`1`
                    match term.is_placeholder() {
                        true => placeholder_index = i,
                        false => v.push(term),
                    }
                }
                // æ„é€  & è¿”å›
                Term::new(
                    identifier,
                    TermComponents::MultiIndexed(placeholder_index, v),
                )
            }
            // é€šç”¨ / åŸå­è¯é¡¹
            // * ğŸ“„è¯è¯­
            // * ğŸ“„å˜é‡
            (_, Atom { name, .. }) => Term::new(identifier, TermComponents::Named(name)),
            // é€šç”¨ / å¤åˆè¯é¡¹ | é»˜è®¤è§†ä½œæœ‰åº
            // * ğŸ“„ä¹˜ç§¯
            (_, Compound { terms, .. }) => Term::new(
                identifier,
                TermComponents::Multi(vec_from_lexical_terms(terms)?),
            ),
            // é€šç”¨ / é›†åˆè¯é¡¹ | é»˜è®¤è§†ä½œæ— åº
            // * ğŸ“„å¤–å»¶é›†ã€å†…æ¶µé›†
            (_, Set { terms, .. }) => Term::new(
                identifier,
                // è§†ä½œã€Œå¤šå…ƒé›†åˆã€ï¼šæ’åº & å»é‡
                TermComponents::new_multi_set(vec_from_lexical_terms(terms)?),
            ),
            // é€šç”¨ / é™ˆè¿° | é»˜è®¤è§†ä½œæœ‰åº
            // * ğŸ“„ç»§æ‰¿ã€è•´å«
            (
                _,
                Statement {
                    subject, predicate, ..
                },
            ) => Term::new(
                identifier,
                TermComponents::Binary(
                    subject.try_fold_into(&())?,
                    predicate.try_fold_into(&())?,
                ),
            ),
            // // å…¶å®ƒâ‡’è¿”å›é”™è¯¯
            // ! ğŸš©ã€2024-04-21 01:38:15ã€‘å·²ç©·å°½
            // _ => return Err(anyhow!("æœªçŸ¥è¯é¡¹æ ‡è¯†ç¬¦ï¼š{identifier:?}")),
        };
        Ok(term)
    } */
}

/// åŸºäºã€Œè¯æ³•æŠ˜å ã€å®ç°[`TryFrom`]
impl TryFrom<TermLexical> for Term {
    type Error = anyhow::Error;

    #[inline(always)]
    fn try_from(value: TermLexical) -> Result<Self, Self::Error> {
        value.try_fold_into(&())
    }
}

/// å­—ç¬¦ä¸²è§£æè·¯çº¿ï¼šè¯æ³•è§£æ â‡’ è¯æ³•æŠ˜å 
/// * ğŸ¯åŒæ—¶å…¼å®¹[`str::parse`]ä¸[`str::try_into`]
impl TryFrom<&str> for Term {
    type Error = anyhow::Error;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        // è¯æ³•è§£æ
        let lexical = FORMAT_ASCII.parse(s)?;
        // è¯æ³•è½¬æ¢ | âš ï¸å¯¹ã€Œè¯­å¥ã€ã€Œä»»åŠ¡ã€æŠ¥é”™
        let term = lexical.try_into_term()?;
        // è¯æ³•æŠ˜å 
        let term = term.try_into()?;
        // è¿”å›
        Ok(term)
    }
}

///  å­—ç¬¦ä¸²è§£æ
/// * ğŸ¯åŒæ—¶å…¼å®¹[`str::parse`]ä¸[`str::try_into`]
impl FromStr for Term {
    type Err = anyhow::Error;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        s.try_into()
    }
}

/// å•å…ƒæµ‹è¯•
#[cfg(test)]
mod tests {
    use super::*;
    use narsese::{
        conversion::{
            inter_type::lexical_fold::TryFoldInto,
            string::impl_lexical::format_instances::FORMAT_ASCII,
        },
        lexical::Term as LexicalTerm,
        lexical_nse_term,
    };

    /// æµ‹è¯• / è¯æ³•æŠ˜å 
    #[test]
    fn test_lexical_fold() -> Result<()> {
        fn fold(t: LexicalTerm) -> Result<Term> {
            print!("{:?} => ", FORMAT_ASCII.format(&t));
            let term: Term = t.try_fold_into(&())?;
            println!("{:?}", term.format_name());
            Ok(term)
        }
        fold(lexical_nse_term!(<A --> B>))?;
        fold(lexical_nse_term!((&&, C, B, A, (/, A, _, B))))?;
        fold(lexical_nse_term!(<(*, {SELF}, x, y) --> ^left>))?;
        fold(lexical_nse_term!([2, 1, 0, $0, #1, ?2]))?;
        fold(lexical_nse_term!(<A <-> {A}>))?;
        fold(lexical_nse_term!(<{B} <=> B>))?;
        fold(lexical_nse_term!(<{SELF} ==> (--, [good])>))?;
        Ok(())
    }
}
